{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feccd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "dummy_input = torch.randn(1, 2, 1024, device=device)\n",
    "onnx_path = \"../models/amc_model.onnx\"\n",
    "\n",
    "torch.onnx.export(model, dummy_input, onnx_path, \n",
    "                  input_names=['input'], output_names=['output'], \n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
    "\n",
    "print(f\"Model exported to {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f43667",
   "metadata": {},
   "source": [
    "## 5. Export to ONNX\n",
    "Export the trained PyTorch model to ONNX format for use in the Inference UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985708d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f1ef1",
   "metadata": {},
   "source": [
    "## 4. Training Loop\n",
    "Train the model for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN1D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(2, 64, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        # 1024 -> 512 -> 256\n",
    "        self.flatten_size = 128 * 256\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.flatten_size)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN1D(num_classes=start_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e3971",
   "metadata": {},
   "source": [
    "## 3. Define Model\n",
    "A simple 1D CNN architecture for modulation classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ab942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose to (N, Channels, Length)\n",
    "X_transposed = X.transpose(0, 2, 1).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transposed, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f347e",
   "metadata": {},
   "source": [
    "## 2. Preprocessing & Splitting\n",
    "Split the data into training and validation sets. We also transpose the data to `(N, C, L)` format required by PyTorch 1D convolutions if needed, but our data is `(N, 1024, 2)`.\n",
    "Common RF CNNs like ResNet1D expect `(N, Channels, Length)`.\n",
    "So `(N, 1024, 2)` -> `(N, 2, 1024)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac79777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../models/data/rf_dataset.pkl'\n",
    "\n",
    "with open(DATA_PATH, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "X = dataset['data']\n",
    "y = dataset['labels']\n",
    "snr = dataset['snr']\n",
    "\n",
    "print(f\"Loaded dataset: X shape {X.shape}, y shape {y.shape}\")\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "start_classes = len(np.unique(y_encoded))\n",
    "print(f\"Classes: {le.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58c1ee7",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "Load the pickle file generated from `dataset_generation.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
