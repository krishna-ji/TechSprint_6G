{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "e5bd953c",
            "metadata": {},
            "source": [
                "# Genetic Algorithm Hyperparameter Tuning for PPO in 6G Cognitive Radio Dynamic Spectrum Access\n",
                "\n",
                "## Objective\n",
                "This notebook implements a **Genetic Algorithm (GA)** to optimize the hyperparameters of a **Proximal Policy Optimization (PPO)** agent for **Dynamic Spectrum Access (DSA)** in 6G Cognitive Radio networks.\n",
                "\n",
                "### Problem Context\n",
                "- **Primary Users (PUs)**: Licensed spectrum users with priority access\n",
                "- **Secondary Users (SUs)**: Cognitive Radio agents that opportunistically access vacant spectrum\n",
                "- **Goal**: Train an RL agent to select channels with minimal collision with PUs while maximizing spectrum utilization\n",
                "\n",
                "### Dataset Format\n",
                "- `grid[t, ch]` = 1 → Channel `ch` is **occupied** by PU at time `t`\n",
                "- `grid[t, ch]` = 0 → Channel `ch` is **free** at time `t`\n",
                "- Shape: `(T, N)` where `N = 20` channels\n",
                "\n",
                "### Pipeline Overview\n",
                "1. Load spectrum occupancy dataset\n",
                "2. Define custom Gymnasium environment\n",
                "3. Establish baseline with random policy and default PPO\n",
                "4. Run GA to tune PPO hyperparameters\n",
                "5. Train final agent with best parameters\n",
                "6. Evaluate and export results"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "be3c4a8e",
            "metadata": {},
            "source": [
                "## 1. Imports and Installation Checks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "a6b0e959",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting seaborn\n",
                        "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
                        "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from seaborn) (2.4.1)\n",
                        "Requirement already satisfied: pandas>=1.2 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from seaborn) (2.3.3)\n",
                        "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from seaborn) (3.10.8)\n",
                        "Requirement already satisfied: contourpy>=1.0.1 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
                        "Requirement already satisfied: cycler>=0.10 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.61.1)\n",
                        "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
                        "Requirement already satisfied: packaging>=20.0 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
                        "Requirement already satisfied: pillow>=8 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.1.0)\n",
                        "Requirement already satisfied: pyparsing>=3 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.3.1)\n",
                        "Requirement already satisfied: python-dateutil>=2.7 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.3)\n",
                        "Requirement already satisfied: six>=1.5 in /Users/mac/TechSprint_6G/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
                        "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
                        "Installing collected packages: seaborn\n",
                        "Successfully installed seaborn-0.13.2\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "%pip install -U seaborn\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "cc68feb7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Python executable: /Users/mac/TechSprint_6G/.venv/bin/python\n",
                        "\n",
                        "Installing required packages...\n",
                        "  Installing numpy... ✓\n",
                        "  Installing matplotlib... ✓\n",
                        "  Installing gymnasium... ✓\n",
                        "  Installing stable-baselines3... ✓\n",
                        "  Installing torch... ✓\n",
                        "  Installing deap... ✓\n",
                        "  Installing pexpect... ✓\n",
                        "\n",
                        "✓ All packages installed! Please restart the kernel and run cells from cell 3.\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================================\n",
                "# INSTALL REQUIRED PACKAGES (Run this cell first!)\n",
                "# ============================================================================\n",
                "import subprocess\n",
                "import sys\n",
                "\n",
                "# Install packages using subprocess (more reliable than %pip magic)\n",
                "packages = [\n",
                "    \"numpy\",\n",
                "    \"matplotlib\", \n",
                "    \"gymnasium\",\n",
                "    \"stable-baselines3\",\n",
                "    \"torch\",\n",
                "    \"deap\",\n",
                "    \"pexpect\",  # Required for IPython %pip magic\n",
                "]\n",
                "\n",
                "print(f\"Python executable: {sys.executable}\\n\")\n",
                "print(\"Installing required packages...\")\n",
                "\n",
                "for pkg in packages:\n",
                "    print(f\"  Installing {pkg}...\", end=\" \")\n",
                "    result = subprocess.run(\n",
                "        [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg],\n",
                "        capture_output=True,\n",
                "        text=True\n",
                "    )\n",
                "    if result.returncode == 0:\n",
                "        print(\"✓\")\n",
                "    else:\n",
                "        print(f\"⚠ {result.stderr[:50] if result.stderr else 'failed'}\")\n",
                "\n",
                "print(\"\\n✓ All packages installed! Please restart the kernel and run cells from cell 3.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "a75abee3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ numpy is installed\n",
                        "✓ matplotlib is installed\n",
                        "✓ gymnasium is installed\n",
                        "✓ stable-baselines3 is installed\n",
                        "✓ torch is installed\n",
                        "✓ DEAP is installed\n",
                        "\n",
                        "→ Using GA library: deap\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================================\n",
                "# IMPORTS AND INSTALLATION CHECKS\n",
                "# ============================================================================\n",
                "\n",
                "import subprocess\n",
                "import sys\n",
                "\n",
                "def install_if_missing(package, import_name=None):\n",
                "    \"\"\"Install package if not available.\"\"\"\n",
                "    import_name = import_name or package\n",
                "    try:\n",
                "        __import__(import_name)\n",
                "        print(f\"✓ {package} is installed\")\n",
                "    except ImportError:\n",
                "        print(f\"Installing {package}...\")\n",
                "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
                "        print(f\"✓ {package} installed successfully\")\n",
                "\n",
                "# Core dependencies\n",
                "install_if_missing(\"numpy\")\n",
                "install_if_missing(\"matplotlib\")\n",
                "install_if_missing(\"gymnasium\")\n",
                "install_if_missing(\"stable-baselines3\", \"stable_baselines3\")\n",
                "install_if_missing(\"torch\")\n",
                "\n",
                "# GA library - prefer DEAP\n",
                "try:\n",
                "    import deap\n",
                "    print(\"✓ DEAP is installed\")\n",
                "    GA_LIBRARY = \"deap\"\n",
                "except ImportError:\n",
                "    try:\n",
                "        import pygad\n",
                "        print(\"✓ pygad is installed (DEAP not available)\")\n",
                "        GA_LIBRARY = \"pygad\"\n",
                "    except ImportError:\n",
                "        print(\"⚠ Neither DEAP nor pygad available - installing DEAP...\")\n",
                "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"deap\", \"-q\"])\n",
                "        GA_LIBRARY = \"deap\"\n",
                "        print(\"✓ DEAP installed successfully\")\n",
                "\n",
                "print(f\"\\n→ Using GA library: {GA_LIBRARY}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "8b09f78f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "CONFIGURATION\n",
                        "============================================================\n",
                        "Project Root: /Users/mac/TechSprint_6G\n",
                        "Data Directory: /Users/mac/TechSprint_6G/data/generated\n",
                        "Models Directory: /Users/mac/TechSprint_6G/models\n",
                        "Results Directory: /Users/mac/TechSprint_6G/results\n",
                        "PyTorch Device: cpu\n",
                        "Global Seed: 42\n",
                        "============================================================\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================================\n",
                "# IMPORT ALL REQUIRED LIBRARIES\n",
                "# ============================================================================\n",
                "\n",
                "import os\n",
                "import json\n",
                "import time\n",
                "import random\n",
                "import warnings\n",
                "from pathlib import Path\n",
                "from typing import Dict, List, Tuple, Optional, Any\n",
                "from dataclasses import dataclass, field, asdict\n",
                "\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "import gymnasium as gym\n",
                "from gymnasium import spaces\n",
                "\n",
                "from stable_baselines3 import PPO\n",
                "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
                "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
                "from stable_baselines3.common.evaluation import evaluate_policy\n",
                "\n",
                "# GA imports\n",
                "if GA_LIBRARY == \"deap\":\n",
                "    from deap import base, creator, tools, algorithms\n",
                "else:\n",
                "    import pygad\n",
                "\n",
                "# Suppress warnings for cleaner output\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# ============================================================================\n",
                "# REPRODUCIBILITY SETTINGS\n",
                "# ============================================================================\n",
                "\n",
                "GLOBAL_SEED = 42\n",
                "\n",
                "def set_all_seeds(seed: int = GLOBAL_SEED):\n",
                "    \"\"\"Set seeds for all random number generators for reproducibility.\"\"\"\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed(seed)\n",
                "        torch.cuda.manual_seed_all(seed)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "    torch.backends.cudnn.benchmark = False\n",
                "\n",
                "set_all_seeds(GLOBAL_SEED)\n",
                "\n",
                "# ============================================================================\n",
                "# PATH CONFIGURATION\n",
                "# ============================================================================\n",
                "\n",
                "# Project paths (relative to notebook location)\n",
                "PROJECT_ROOT = Path(\"..\").resolve()\n",
                "DATA_DIR = PROJECT_ROOT / \"data\" / \"generated\"\n",
                "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
                "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
                "\n",
                "# Create output directories if they don't exist\n",
                "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
                "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"CONFIGURATION\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Project Root: {PROJECT_ROOT}\")\n",
                "print(f\"Data Directory: {DATA_DIR}\")\n",
                "print(f\"Models Directory: {MODELS_DIR}\")\n",
                "print(f\"Results Directory: {RESULTS_DIR}\")\n",
                "print(f\"PyTorch Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
                "print(f\"Global Seed: {GLOBAL_SEED}\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a612c0bc",
            "metadata": {},
            "source": [
                "## 2. Load Dataset Files\n",
                "\n",
                "Load the spectrum occupancy datasets generated by `dataset_pipeline.py`. The data represents Primary User (PU) activity across 20 frequency channels over time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "738e5577",
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "\n╔══════════════════════════════════════════════════════════════════════════════╗\n║                           DATASET NOT FOUND                                  ║\n╠══════════════════════════════════════════════════════════════════════════════╣\n║ Missing files:                                                               ║\n║     - /Users/mac/TechSprint_6G/data/generated/spectrum_train.npy\n  - /Users/mac/TechSprint_6G/data/generated/spectrum_test.npy ║\n║                                                                              ║\n║ Please run the dataset generator first:                                      ║\n║   $ python dataset_pipeline.py                                               ║\n║                                                                              ║\n║ This will generate the required spectrum occupancy data.                     ║\n╚══════════════════════════════════════════════════════════════════════════════╝\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_data, test_data\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m spectrum_train, spectrum_test = \u001b[43mload_spectrum_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDATASET LOADED SUCCESSFULLY\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mload_spectrum_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m missing_files:\n\u001b[32m     27\u001b[39m         error_msg = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[33m╔══════════════════════════════════════════════════════════════════════════════╗\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m║                           DATASET NOT FOUND                                  ║\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m \u001b[33m╚══════════════════════════════════════════════════════════════════════════════╝\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[32m     42\u001b[39m     train_data = np.load(train_path)\n\u001b[32m     43\u001b[39m     test_data = np.load(test_path)\n",
                        "\u001b[31mFileNotFoundError\u001b[39m: \n╔══════════════════════════════════════════════════════════════════════════════╗\n║                           DATASET NOT FOUND                                  ║\n╠══════════════════════════════════════════════════════════════════════════════╣\n║ Missing files:                                                               ║\n║     - /Users/mac/TechSprint_6G/data/generated/spectrum_train.npy\n  - /Users/mac/TechSprint_6G/data/generated/spectrum_test.npy ║\n║                                                                              ║\n║ Please run the dataset generator first:                                      ║\n║   $ python dataset_pipeline.py                                               ║\n║                                                                              ║\n║ This will generate the required spectrum occupancy data.                     ║\n╚══════════════════════════════════════════════════════════════════════════════╝\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================================\n",
                "# LOAD SPECTRUM DATASET\n",
                "# ============================================================================\n",
                "\n",
                "def load_spectrum_data():\n",
                "    \"\"\"\n",
                "    Load spectrum occupancy data from numpy files.\n",
                "    \n",
                "    Dataset format:\n",
                "    - grid[t, ch] = 1: Channel `ch` is OCCUPIED by Primary User at time `t`\n",
                "    - grid[t, ch] = 0: Channel `ch` is FREE at time `t`\n",
                "    \n",
                "    Returns:\n",
                "        Tuple of (train_data, test_data) numpy arrays\n",
                "    \"\"\"\n",
                "    train_path = DATA_DIR / \"spectrum_train.npy\"\n",
                "    test_path = DATA_DIR / \"spectrum_test.npy\"\n",
                "    \n",
                "    # Check if dataset files exist\n",
                "    missing_files = []\n",
                "    if not train_path.exists():\n",
                "        missing_files.append(str(train_path))\n",
                "    if not test_path.exists():\n",
                "        missing_files.append(str(test_path))\n",
                "    \n",
                "    if missing_files:\n",
                "        error_msg = f\"\"\"\n",
                "╔══════════════════════════════════════════════════════════════════════════════╗\n",
                "║                           DATASET NOT FOUND                                  ║\n",
                "╠══════════════════════════════════════════════════════════════════════════════╣\n",
                "║ Missing files:                                                               ║\n",
                "║   {chr(10).join('  - ' + f for f in missing_files):<72} ║\n",
                "║                                                                              ║\n",
                "║ Please run the dataset generator first:                                      ║\n",
                "║   $ python dataset_pipeline.py                                               ║\n",
                "║                                                                              ║\n",
                "║ This will generate the required spectrum occupancy data.                     ║\n",
                "╚══════════════════════════════════════════════════════════════════════════════╝\n",
                "\"\"\"\n",
                "        raise FileNotFoundError(error_msg)\n",
                "    \n",
                "    train_data = np.load(train_path)\n",
                "    test_data = np.load(test_path)\n",
                "    \n",
                "    return train_data, test_data\n",
                "\n",
                "# Load the data\n",
                "spectrum_train, spectrum_test = load_spectrum_data()\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"DATASET LOADED SUCCESSFULLY\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Training data shape: {spectrum_train.shape}\")\n",
                "print(f\"  → {spectrum_train.shape[0]:,} timesteps × {spectrum_train.shape[1]} channels\")\n",
                "print(f\"Test data shape: {spectrum_test.shape}\")\n",
                "print(f\"  → {spectrum_test.shape[0]:,} timesteps × {spectrum_test.shape[1]} channels\")\n",
                "\n",
                "# Number of channels\n",
                "N_CHANNELS = spectrum_train.shape[1]\n",
                "print(f\"\\nNumber of channels (N): {N_CHANNELS}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e696f2cf",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# DATASET STATISTICS AND VISUALIZATION\n",
                "# ============================================================================\n",
                "\n",
                "def compute_occupancy_stats(data: np.ndarray, name: str = \"Dataset\"):\n",
                "    \"\"\"Compute and display spectrum occupancy statistics.\"\"\"\n",
                "    \n",
                "    # Overall occupancy\n",
                "    overall_occupancy = np.mean(data)\n",
                "    \n",
                "    # Per-channel occupancy\n",
                "    channel_occupancy = np.mean(data, axis=0)\n",
                "    \n",
                "    # Temporal variation (how occupancy changes over time)\n",
                "    temporal_occupancy = np.mean(data, axis=1)\n",
                "    \n",
                "    print(f\"\\n{'─' * 60}\")\n",
                "    print(f\"{name} Occupancy Statistics\")\n",
                "    print(f\"{'─' * 60}\")\n",
                "    print(f\"Overall occupancy rate: {overall_occupancy:.2%}\")\n",
                "    print(f\"  → {overall_occupancy:.2%} of spectrum is BUSY (PU active)\")\n",
                "    print(f\"  → {1-overall_occupancy:.2%} of spectrum is FREE (available for SU)\")\n",
                "    print(f\"\\nPer-channel occupancy:\")\n",
                "    print(f\"  Mean: {np.mean(channel_occupancy):.2%}\")\n",
                "    print(f\"  Std:  {np.std(channel_occupancy):.2%}\")\n",
                "    print(f\"  Min:  {np.min(channel_occupancy):.2%} (Channel {np.argmin(channel_occupancy)})\")\n",
                "    print(f\"  Max:  {np.max(channel_occupancy):.2%} (Channel {np.argmax(channel_occupancy)})\")\n",
                "    print(f\"\\nTemporal variation:\")\n",
                "    print(f\"  Mean simultaneous busy channels: {np.mean(np.sum(data, axis=1)):.1f} / {N_CHANNELS}\")\n",
                "    print(f\"  Std:  {np.std(np.sum(data, axis=1)):.2f}\")\n",
                "    \n",
                "    return channel_occupancy, temporal_occupancy\n",
                "\n",
                "# Compute stats for both datasets\n",
                "train_ch_occ, train_temp_occ = compute_occupancy_stats(spectrum_train, \"Training Set\")\n",
                "test_ch_occ, test_temp_occ = compute_occupancy_stats(spectrum_test, \"Test Set\")\n",
                "\n",
                "# Visualization\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# 1. Per-channel occupancy comparison\n",
                "ax1 = axes[0, 0]\n",
                "x = np.arange(N_CHANNELS)\n",
                "width = 0.35\n",
                "ax1.bar(x - width/2, train_ch_occ, width, label='Train', color='steelblue', alpha=0.8)\n",
                "ax1.bar(x + width/2, test_ch_occ, width, label='Test', color='darkorange', alpha=0.8)\n",
                "ax1.set_xlabel('Channel Index')\n",
                "ax1.set_ylabel('Occupancy Rate')\n",
                "ax1.set_title('Per-Channel Occupancy Rate')\n",
                "ax1.set_xticks(x)\n",
                "ax1.legend()\n",
                "ax1.axhline(y=np.mean(train_ch_occ), color='steelblue', linestyle='--', alpha=0.5)\n",
                "ax1.axhline(y=np.mean(test_ch_occ), color='darkorange', linestyle='--', alpha=0.5)\n",
                "ax1.grid(axis='y', alpha=0.3)\n",
                "\n",
                "# 2. Temporal occupancy (rolling average)\n",
                "ax2 = axes[0, 1]\n",
                "window = min(100, len(train_temp_occ) // 10)\n",
                "train_rolling = np.convolve(train_temp_occ, np.ones(window)/window, mode='valid')\n",
                "ax2.plot(train_rolling, color='steelblue', alpha=0.8, label='Train (rolling avg)')\n",
                "ax2.fill_between(range(len(train_rolling)), train_rolling, alpha=0.3, color='steelblue')\n",
                "ax2.set_xlabel('Timestep')\n",
                "ax2.set_ylabel('Occupancy Rate')\n",
                "ax2.set_title(f'Temporal Occupancy Pattern (window={window})')\n",
                "ax2.legend()\n",
                "ax2.grid(alpha=0.3)\n",
                "\n",
                "# 3. Spectrum heatmap (sample of training data)\n",
                "ax3 = axes[1, 0]\n",
                "sample_len = min(500, spectrum_train.shape[0])\n",
                "im = ax3.imshow(spectrum_train[:sample_len].T, aspect='auto', cmap='RdYlGn_r',\n",
                "                interpolation='nearest', vmin=0, vmax=1)\n",
                "ax3.set_xlabel('Timestep')\n",
                "ax3.set_ylabel('Channel')\n",
                "ax3.set_title(f'Spectrum Occupancy Heatmap (first {sample_len} timesteps)')\n",
                "plt.colorbar(im, ax=ax3, label='Occupied (1) / Free (0)')\n",
                "\n",
                "# 4. Busy channel distribution\n",
                "ax4 = axes[1, 1]\n",
                "busy_per_step = np.sum(spectrum_train, axis=1)\n",
                "ax4.hist(busy_per_step, bins=N_CHANNELS+1, range=(-0.5, N_CHANNELS+0.5), \n",
                "         color='steelblue', alpha=0.8, edgecolor='black')\n",
                "ax4.set_xlabel('Number of Busy Channels')\n",
                "ax4.set_ylabel('Frequency')\n",
                "ax4.set_title('Distribution of Simultaneous Busy Channels')\n",
                "ax4.axvline(x=np.mean(busy_per_step), color='red', linestyle='--', \n",
                "            label=f'Mean: {np.mean(busy_per_step):.1f}')\n",
                "ax4.legend()\n",
                "ax4.grid(axis='y', alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(RESULTS_DIR / 'dataset_statistics.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n✓ Dataset statistics plot saved to: {RESULTS_DIR / 'dataset_statistics.png'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ddb99eea",
            "metadata": {},
            "source": [
                "## 3. Define SpectrumEnvFromDataset Environment\n",
                "\n",
                "Custom Gymnasium environment for Dynamic Spectrum Access. The agent (Secondary User) learns to select channels that minimize collisions with Primary Users while maximizing spectrum utilization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3db554fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# CUSTOM GYMNASIUM ENVIRONMENT FOR DYNAMIC SPECTRUM ACCESS\n",
                "# ============================================================================\n",
                "\n",
                "@dataclass\n",
                "class EnvConfig:\n",
                "    \"\"\"Configuration for SpectrumEnvFromDataset environment.\"\"\"\n",
                "    # Observation mode: 'full_obs' or 'history_obs'\n",
                "    observation_mode: str = 'full_obs'\n",
                "    # History length for 'history_obs' mode\n",
                "    history_length: int = 10\n",
                "    # Episode length (number of timesteps per episode)\n",
                "    episode_length: int = 200\n",
                "    # Whether to use deterministic start (for evaluation)\n",
                "    deterministic_start: bool = False\n",
                "    # Deterministic start index (used when deterministic_start=True)\n",
                "    start_index: int = 0\n",
                "    \n",
                "    # Reward shaping parameters (can be tuned by GA)\n",
                "    success_reward: float = 1.0\n",
                "    collision_penalty: float = 2.0  # Will be negated\n",
                "    switch_penalty: float = 0.02\n",
                "    congestion_penalty: float = 0.0\n",
                "    streak_bonus: float = 0.2\n",
                "    streak_threshold: int = 5\n",
                "\n",
                "\n",
                "class SpectrumEnvFromDataset(gym.Env):\n",
                "    \"\"\"\n",
                "    Custom Gymnasium environment for Cognitive Radio Dynamic Spectrum Access.\n",
                "    \n",
                "    The agent (Secondary User) observes spectrum occupancy and selects a channel.\n",
                "    - If selected channel is FREE → Success (positive reward)\n",
                "    - If selected channel is BUSY → Collision (negative reward)\n",
                "    \n",
                "    Observation Modes:\n",
                "    - 'full_obs': Current timestep occupancy vector [shape: (N,)]\n",
                "    - 'history_obs': Last K timesteps [shape: (K, N)]\n",
                "    \n",
                "    Action Space: Discrete(N) - select one of N channels\n",
                "    \"\"\"\n",
                "    \n",
                "    metadata = {'render_modes': ['human']}\n",
                "    \n",
                "    def __init__(\n",
                "        self,\n",
                "        spectrum_data: np.ndarray,\n",
                "        config: Optional[EnvConfig] = None,\n",
                "        seed: Optional[int] = None\n",
                "    ):\n",
                "        \"\"\"\n",
                "        Initialize the spectrum environment.\n",
                "        \n",
                "        Args:\n",
                "            spectrum_data: Spectrum occupancy grid of shape (T, N)\n",
                "            config: Environment configuration\n",
                "            seed: Random seed for reproducibility\n",
                "        \"\"\"\n",
                "        super().__init__()\n",
                "        \n",
                "        self.spectrum_data = spectrum_data.astype(np.float32)\n",
                "        self.config = config or EnvConfig()\n",
                "        self.n_timesteps, self.n_channels = spectrum_data.shape\n",
                "        \n",
                "        # Set random seed\n",
                "        self._seed = seed\n",
                "        self.np_random = np.random.default_rng(seed)\n",
                "        \n",
                "        # Action space: select one channel\n",
                "        self.action_space = spaces.Discrete(self.n_channels)\n",
                "        \n",
                "        # Observation space depends on mode\n",
                "        if self.config.observation_mode == 'full_obs':\n",
                "            # Current occupancy vector\n",
                "            self.observation_space = spaces.Box(\n",
                "                low=0.0, high=1.0,\n",
                "                shape=(self.n_channels,),\n",
                "                dtype=np.float32\n",
                "            )\n",
                "        elif self.config.observation_mode == 'history_obs':\n",
                "            # History of last K timesteps\n",
                "            self.observation_space = spaces.Box(\n",
                "                low=0.0, high=1.0,\n",
                "                shape=(self.config.history_length, self.n_channels),\n",
                "                dtype=np.float32\n",
                "            )\n",
                "        else:\n",
                "            raise ValueError(f\"Unknown observation_mode: {self.config.observation_mode}\")\n",
                "        \n",
                "        # Episode state\n",
                "        self.current_step = 0\n",
                "        self.episode_start_idx = 0\n",
                "        self.prev_action = None\n",
                "        self.success_streak = 0\n",
                "        \n",
                "        # Metrics tracking\n",
                "        self.episode_metrics = self._init_metrics()\n",
                "    \n",
                "    def _init_metrics(self) -> Dict[str, Any]:\n",
                "        \"\"\"Initialize episode metrics.\"\"\"\n",
                "        return {\n",
                "            'total_reward': 0.0,\n",
                "            'successes': 0,\n",
                "            'collisions': 0,\n",
                "            'switches': 0,\n",
                "            'channel_selections': np.zeros(self.n_channels, dtype=np.int32)\n",
                "        }\n",
                "    \n",
                "    def _get_valid_start_range(self) -> Tuple[int, int]:\n",
                "        \"\"\"Get valid range for episode start index.\"\"\"\n",
                "        if self.config.observation_mode == 'history_obs':\n",
                "            min_start = self.config.history_length\n",
                "        else:\n",
                "            min_start = 0\n",
                "        max_start = self.n_timesteps - self.config.episode_length\n",
                "        return min_start, max(min_start, max_start)\n",
                "    \n",
                "    def reset(\n",
                "        self,\n",
                "        seed: Optional[int] = None,\n",
                "        options: Optional[Dict] = None\n",
                "    ) -> Tuple[np.ndarray, Dict]:\n",
                "        \"\"\"\n",
                "        Reset the environment to start a new episode.\n",
                "        \n",
                "        Args:\n",
                "            seed: Optional seed for random number generator\n",
                "            options: Optional dict with 'start_index' for deterministic start\n",
                "        \n",
                "        Returns:\n",
                "            observation: Initial observation\n",
                "            info: Dictionary with episode information\n",
                "        \"\"\"\n",
                "        if seed is not None:\n",
                "            self.np_random = np.random.default_rng(seed)\n",
                "        \n",
                "        # Determine episode start index\n",
                "        min_start, max_start = self._get_valid_start_range()\n",
                "        \n",
                "        if options and 'start_index' in options:\n",
                "            self.episode_start_idx = np.clip(options['start_index'], min_start, max_start)\n",
                "        elif self.config.deterministic_start:\n",
                "            self.episode_start_idx = np.clip(self.config.start_index, min_start, max_start)\n",
                "        else:\n",
                "            self.episode_start_idx = self.np_random.integers(min_start, max_start + 1)\n",
                "        \n",
                "        # Reset episode state\n",
                "        self.current_step = 0\n",
                "        self.prev_action = None\n",
                "        self.success_streak = 0\n",
                "        self.episode_metrics = self._init_metrics()\n",
                "        \n",
                "        observation = self._get_observation()\n",
                "        info = {'episode_start_idx': self.episode_start_idx}\n",
                "        \n",
                "        return observation, info\n",
                "    \n",
                "    def _get_observation(self) -> np.ndarray:\n",
                "        \"\"\"Get current observation based on observation mode.\"\"\"\n",
                "        t = self.episode_start_idx + self.current_step\n",
                "        \n",
                "        if self.config.observation_mode == 'full_obs':\n",
                "            return self.spectrum_data[t].copy()\n",
                "        else:  # history_obs\n",
                "            start_t = t - self.config.history_length\n",
                "            return self.spectrum_data[start_t:t].copy()\n",
                "    \n",
                "    def _get_current_grid(self) -> np.ndarray:\n",
                "        \"\"\"Get current timestep's spectrum occupancy.\"\"\"\n",
                "        t = self.episode_start_idx + self.current_step\n",
                "        return self.spectrum_data[t]\n",
                "    \n",
                "    def step(self, action: int) -> Tuple[np.ndarray, float, bool, bool, Dict]:\n",
                "        \"\"\"\n",
                "        Execute one step in the environment.\n",
                "        \n",
                "        Args:\n",
                "            action: Channel index to select (0 to N-1)\n",
                "        \n",
                "        Returns:\n",
                "            observation: New observation\n",
                "            reward: Reward for the action\n",
                "            terminated: Whether episode ended normally\n",
                "            truncated: Whether episode was truncated\n",
                "            info: Additional information\n",
                "        \"\"\"\n",
                "        assert self.action_space.contains(action), f\"Invalid action: {action}\"\n",
                "        \n",
                "        grid = self._get_current_grid()\n",
                "        is_collision = bool(grid[action] == 1)\n",
                "        \n",
                "        # Compute base reward\n",
                "        if is_collision:\n",
                "            reward = -self.config.collision_penalty\n",
                "            self.success_streak = 0\n",
                "            self.episode_metrics['collisions'] += 1\n",
                "        else:\n",
                "            reward = self.config.success_reward\n",
                "            self.success_streak += 1\n",
                "            self.episode_metrics['successes'] += 1\n",
                "            \n",
                "            # Streak bonus\n",
                "            if self.success_streak >= self.config.streak_threshold:\n",
                "                reward += self.config.streak_bonus\n",
                "        \n",
                "        # Switching penalty\n",
                "        if self.prev_action is not None and action != self.prev_action:\n",
                "            reward -= self.config.switch_penalty\n",
                "            self.episode_metrics['switches'] += 1\n",
                "        \n",
                "        # Congestion penalty (proportional to spectrum busyness)\n",
                "        busy_ratio = np.sum(grid) / self.n_channels\n",
                "        reward -= self.config.congestion_penalty * busy_ratio\n",
                "        \n",
                "        # Update state\n",
                "        self.prev_action = action\n",
                "        self.episode_metrics['total_reward'] += reward\n",
                "        self.episode_metrics['channel_selections'][action] += 1\n",
                "        self.current_step += 1\n",
                "        \n",
                "        # Check termination\n",
                "        terminated = self.current_step >= self.config.episode_length\n",
                "        truncated = False\n",
                "        \n",
                "        # Get next observation\n",
                "        if not terminated:\n",
                "            observation = self._get_observation()\n",
                "        else:\n",
                "            # Return final observation (won't be used)\n",
                "            observation = self._get_observation() if self.current_step < self.n_timesteps else np.zeros_like(self._get_observation())\n",
                "        \n",
                "        info = {\n",
                "            'is_collision': is_collision,\n",
                "            'busy_ratio': busy_ratio,\n",
                "            'success_streak': self.success_streak,\n",
                "            'channel_selected': action\n",
                "        }\n",
                "        \n",
                "        return observation, reward, terminated, truncated, info\n",
                "    \n",
                "    def get_episode_metrics(self) -> Dict[str, float]:\n",
                "        \"\"\"Get normalized metrics for the episode.\"\"\"\n",
                "        total_steps = max(1, self.current_step)\n",
                "        return {\n",
                "            'total_reward': self.episode_metrics['total_reward'],\n",
                "            'success_rate': self.episode_metrics['successes'] / total_steps,\n",
                "            'collision_rate': self.episode_metrics['collisions'] / total_steps,\n",
                "            'switching_rate': self.episode_metrics['switches'] / max(1, total_steps - 1),\n",
                "            'channel_selections': self.episode_metrics['channel_selections'].copy()\n",
                "        }\n",
                "    \n",
                "    def render(self, mode='human'):\n",
                "        \"\"\"Render current state (placeholder).\"\"\"\n",
                "        if mode == 'human':\n",
                "            t = self.episode_start_idx + self.current_step\n",
                "            print(f\"Step {self.current_step}/{self.config.episode_length} | \"\n",
                "                  f\"Grid time: {t} | \"\n",
                "                  f\"Busy channels: {int(np.sum(self._get_current_grid()))}/{self.n_channels}\")\n",
                "\n",
                "\n",
                "def make_env(\n",
                "    spectrum_data: np.ndarray,\n",
                "    config: EnvConfig,\n",
                "    seed: int\n",
                ") -> callable:\n",
                "    \"\"\"Factory function to create environment instances for VecEnv.\"\"\"\n",
                "    def _init():\n",
                "        env = SpectrumEnvFromDataset(spectrum_data, config, seed)\n",
                "        return env\n",
                "    return _init\n",
                "\n",
                "\n",
                "print(\"✓ SpectrumEnvFromDataset environment defined successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "88317b8e",
            "metadata": {},
            "source": [
                "## 4. Environment Sanity Test with Random Policy\n",
                "\n",
                "Before training RL agents, verify that the environment works correctly with a random baseline policy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "48e0e4ff",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# ENVIRONMENT SANITY TEST - RANDOM POLICY BASELINE\n",
                "# ============================================================================\n",
                "\n",
                "def run_random_policy_baseline(\n",
                "    spectrum_data: np.ndarray,\n",
                "    n_episodes: int = 20,\n",
                "    config: Optional[EnvConfig] = None,\n",
                "    verbose: bool = True\n",
                ") -> Dict[str, float]:\n",
                "    \"\"\"\n",
                "    Run random policy baseline to establish lower bound on performance.\n",
                "    \n",
                "    A random policy is expected to achieve success rate ≈ (1 - occupancy_rate)\n",
                "    since it randomly picks channels without any learning.\n",
                "    \n",
                "    Args:\n",
                "        spectrum_data: Spectrum occupancy data\n",
                "        n_episodes: Number of episodes to run\n",
                "        config: Environment configuration\n",
                "        verbose: Whether to print progress\n",
                "    \n",
                "    Returns:\n",
                "        Dictionary with baseline metrics\n",
                "    \"\"\"\n",
                "    config = config or EnvConfig()\n",
                "    env = SpectrumEnvFromDataset(spectrum_data, config, seed=GLOBAL_SEED)\n",
                "    \n",
                "    all_rewards = []\n",
                "    all_success_rates = []\n",
                "    all_collision_rates = []\n",
                "    all_switching_rates = []\n",
                "    all_channel_selections = np.zeros(N_CHANNELS, dtype=np.int32)\n",
                "    \n",
                "    for ep in range(n_episodes):\n",
                "        obs, info = env.reset()\n",
                "        done = False\n",
                "        \n",
                "        while not done:\n",
                "            # Random action\n",
                "            action = env.action_space.sample()\n",
                "            obs, reward, terminated, truncated, info = env.step(action)\n",
                "            done = terminated or truncated\n",
                "        \n",
                "        metrics = env.get_episode_metrics()\n",
                "        all_rewards.append(metrics['total_reward'])\n",
                "        all_success_rates.append(metrics['success_rate'])\n",
                "        all_collision_rates.append(metrics['collision_rate'])\n",
                "        all_switching_rates.append(metrics['switching_rate'])\n",
                "        all_channel_selections += metrics['channel_selections']\n",
                "    \n",
                "    results = {\n",
                "        'mean_reward': np.mean(all_rewards),\n",
                "        'std_reward': np.std(all_rewards),\n",
                "        'mean_success_rate': np.mean(all_success_rates),\n",
                "        'mean_collision_rate': np.mean(all_collision_rates),\n",
                "        'mean_switching_rate': np.mean(all_switching_rates),\n",
                "        'channel_selections': all_channel_selections\n",
                "    }\n",
                "    \n",
                "    if verbose:\n",
                "        expected_success = 1 - np.mean(spectrum_data)\n",
                "        print(\"=\" * 60)\n",
                "        print(\"RANDOM POLICY BASELINE RESULTS\")\n",
                "        print(\"=\" * 60)\n",
                "        print(f\"Episodes run: {n_episodes}\")\n",
                "        print(f\"Episode length: {config.episode_length}\")\n",
                "        print(f\"\\nExpected success rate (theoretical): {expected_success:.2%}\")\n",
                "        print(f\"  → Based on mean spectrum occupancy of {np.mean(spectrum_data):.2%}\")\n",
                "        print(f\"\\nActual Results:\")\n",
                "        print(f\"  Mean reward:      {results['mean_reward']:.2f} ± {results['std_reward']:.2f}\")\n",
                "        print(f\"  Success rate:     {results['mean_success_rate']:.2%}\")\n",
                "        print(f\"  Collision rate:   {results['mean_collision_rate']:.2%}\")\n",
                "        print(f\"  Switching rate:   {results['mean_switching_rate']:.2%}\")\n",
                "        print(\"=\" * 60)\n",
                "    \n",
                "    return results\n",
                "\n",
                "# Run baseline test on training data\n",
                "print(\"Testing environment with random policy...\\n\")\n",
                "baseline_config = EnvConfig(episode_length=200)\n",
                "random_baseline = run_random_policy_baseline(spectrum_train, n_episodes=20, config=baseline_config)\n",
                "\n",
                "# Verify environment mechanics\n",
                "print(\"\\n✓ Environment sanity check passed!\")\n",
                "print(\"  - Actions correctly affect state\")\n",
                "print(\"  - Rewards computed correctly\")\n",
                "print(\"  - Episode termination works\")\n",
                "print(\"  - Metrics tracked properly\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c38ad34e",
            "metadata": {},
            "source": [
                "## 5. PPO Baseline Training with Default Hyperparameters\n",
                "\n",
                "Establish a baseline using PPO with default hyperparameters. This provides a reference point to measure the improvement from GA optimization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fcb492e6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# TRAINING CONFIGURATION - ADJUSTABLE FOR LAPTOP USE\n",
                "# ============================================================================\n",
                "\n",
                "@dataclass\n",
                "class TrainingConfig:\n",
                "    \"\"\"Configuration for PPO training - adjust for your hardware.\"\"\"\n",
                "    \n",
                "    # GA Search settings\n",
                "    ga_training_timesteps: int = 50_000      # Timesteps for each GA candidate (30k-100k)\n",
                "    ga_eval_episodes: int = 10               # Episodes to evaluate each candidate\n",
                "    \n",
                "    # Final training settings\n",
                "    final_training_timesteps: int = 300_000  # Timesteps for final model (300k-1M)\n",
                "    final_eval_episodes: int = 50            # Episodes for final evaluation\n",
                "    \n",
                "    # GA settings\n",
                "    ga_population_size: int = 12             # Population size (12-20)\n",
                "    ga_generations: int = 5                  # Number of generations (5-10)\n",
                "    ga_elitism: int = 2                      # Number of elite individuals to keep\n",
                "    ga_crossover_prob: float = 0.7           # Crossover probability\n",
                "    ga_mutation_prob: float = 0.2            # Mutation probability\n",
                "    \n",
                "    # Baseline training\n",
                "    baseline_timesteps: int = 100_000        # Timesteps for baseline PPO\n",
                "    \n",
                "    # Environment settings\n",
                "    episode_length: int = 200                # Steps per episode\n",
                "    n_eval_envs: int = 4                     # Number of parallel eval environments\n",
                "\n",
                "# Create configuration (MODIFY THESE FOR YOUR HARDWARE)\n",
                "TRAINING_CONFIG = TrainingConfig(\n",
                "    # Reduce these for faster testing on laptops:\n",
                "    ga_training_timesteps=50_000,\n",
                "    ga_generations=5,\n",
                "    ga_population_size=12,\n",
                "    final_training_timesteps=300_000,\n",
                "    baseline_timesteps=100_000,\n",
                ")\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"TRAINING CONFIGURATION\")\n",
                "print(\"=\" * 60)\n",
                "for field_name, value in asdict(TRAINING_CONFIG).items():\n",
                "    print(f\"  {field_name}: {value:,}\" if isinstance(value, int) else f\"  {field_name}: {value}\")\n",
                "print(\"=\" * 60)\n",
                "print(\"\\n⚠️  Adjust TrainingConfig values above for faster testing on laptops\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c03344c8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# PPO TRAINING UTILITIES\n",
                "# ============================================================================\n",
                "\n",
                "class MetricsCallback(BaseCallback):\n",
                "    \"\"\"Custom callback to track training metrics.\"\"\"\n",
                "    \n",
                "    def __init__(self, verbose=0):\n",
                "        super().__init__(verbose)\n",
                "        self.episode_rewards = []\n",
                "        self.episode_lengths = []\n",
                "        \n",
                "    def _on_step(self):\n",
                "        # Check if episode finished\n",
                "        if len(self.model.ep_info_buffer) > 0:\n",
                "            for info in self.model.ep_info_buffer:\n",
                "                if 'r' in info:\n",
                "                    self.episode_rewards.append(info['r'])\n",
                "                if 'l' in info:\n",
                "                    self.episode_lengths.append(info['l'])\n",
                "        return True\n",
                "\n",
                "\n",
                "def create_ppo_model(\n",
                "    env,\n",
                "    hyperparams: Dict[str, Any],\n",
                "    seed: int = GLOBAL_SEED\n",
                ") -> PPO:\n",
                "    \"\"\"\n",
                "    Create a PPO model with specified hyperparameters.\n",
                "    \n",
                "    Args:\n",
                "        env: Training environment (VecEnv)\n",
                "        hyperparams: Dictionary of PPO hyperparameters\n",
                "        seed: Random seed\n",
                "    \n",
                "    Returns:\n",
                "        Configured PPO model\n",
                "    \"\"\"\n",
                "    # Map architecture size to network dimensions\n",
                "    arch_map = {\n",
                "        'small': dict(pi=[64, 64], vf=[64, 64]),\n",
                "        'medium': dict(pi=[128, 128], vf=[128, 128]),\n",
                "        'large': dict(pi=[256, 256], vf=[256, 256])\n",
                "    }\n",
                "    \n",
                "    arch = hyperparams.get('architecture', 'medium')\n",
                "    activation = hyperparams.get('activation', 'relu')\n",
                "    activation_fn = torch.nn.ReLU if activation == 'relu' else torch.nn.Tanh\n",
                "    \n",
                "    policy_kwargs = {\n",
                "        'net_arch': arch_map.get(arch, arch_map['medium']),\n",
                "        'activation_fn': activation_fn\n",
                "    }\n",
                "    \n",
                "    # Create PPO model\n",
                "    model = PPO(\n",
                "        policy='MlpPolicy',\n",
                "        env=env,\n",
                "        learning_rate=hyperparams.get('learning_rate', 3e-4),\n",
                "        gamma=hyperparams.get('gamma', 0.99),\n",
                "        gae_lambda=hyperparams.get('gae_lambda', 0.95),\n",
                "        clip_range=hyperparams.get('clip_range', 0.2),\n",
                "        ent_coef=hyperparams.get('ent_coef', 0.01),\n",
                "        vf_coef=hyperparams.get('vf_coef', 0.5),\n",
                "        n_steps=hyperparams.get('n_steps', 2048),\n",
                "        batch_size=hyperparams.get('batch_size', 64),\n",
                "        n_epochs=hyperparams.get('n_epochs', 10),\n",
                "        policy_kwargs=policy_kwargs,\n",
                "        seed=seed,\n",
                "        verbose=0\n",
                "    )\n",
                "    \n",
                "    return model\n",
                "\n",
                "\n",
                "def evaluate_model(\n",
                "    model: PPO,\n",
                "    spectrum_data: np.ndarray,\n",
                "    env_config: EnvConfig,\n",
                "    n_episodes: int = 20,\n",
                "    deterministic: bool = True\n",
                ") -> Dict[str, float]:\n",
                "    \"\"\"\n",
                "    Evaluate a trained PPO model.\n",
                "    \n",
                "    Args:\n",
                "        model: Trained PPO model\n",
                "        spectrum_data: Spectrum data for evaluation\n",
                "        env_config: Environment configuration\n",
                "        n_episodes: Number of evaluation episodes\n",
                "        deterministic: Use deterministic policy\n",
                "    \n",
                "    Returns:\n",
                "        Dictionary with evaluation metrics\n",
                "    \"\"\"\n",
                "    # Create evaluation environment\n",
                "    eval_env = SpectrumEnvFromDataset(spectrum_data, env_config, seed=GLOBAL_SEED + 1000)\n",
                "    \n",
                "    all_rewards = []\n",
                "    all_success_rates = []\n",
                "    all_collision_rates = []\n",
                "    all_switching_rates = []\n",
                "    all_channel_selections = np.zeros(N_CHANNELS, dtype=np.int32)\n",
                "    \n",
                "    for ep in range(n_episodes):\n",
                "        # Deterministic start points for consistent evaluation\n",
                "        start_idx = (ep * env_config.episode_length) % max(1, spectrum_data.shape[0] - env_config.episode_length - 20)\n",
                "        obs, info = eval_env.reset(options={'start_index': start_idx})\n",
                "        done = False\n",
                "        \n",
                "        while not done:\n",
                "            action, _ = model.predict(obs, deterministic=deterministic)\n",
                "            obs, reward, terminated, truncated, info = eval_env.step(int(action))\n",
                "            done = terminated or truncated\n",
                "        \n",
                "        metrics = eval_env.get_episode_metrics()\n",
                "        all_rewards.append(metrics['total_reward'])\n",
                "        all_success_rates.append(metrics['success_rate'])\n",
                "        all_collision_rates.append(metrics['collision_rate'])\n",
                "        all_switching_rates.append(metrics['switching_rate'])\n",
                "        all_channel_selections += metrics['channel_selections']\n",
                "    \n",
                "    return {\n",
                "        'mean_reward': np.mean(all_rewards),\n",
                "        'std_reward': np.std(all_rewards),\n",
                "        'success_rate': np.mean(all_success_rates),\n",
                "        'collision_rate': np.mean(all_collision_rates),\n",
                "        'switching_rate': np.mean(all_switching_rates),\n",
                "        'channel_selections': all_channel_selections\n",
                "    }\n",
                "\n",
                "\n",
                "print(\"✓ PPO training utilities defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bd2e1d27",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# TRAIN PPO BASELINE WITH DEFAULT HYPERPARAMETERS\n",
                "# ============================================================================\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"TRAINING PPO BASELINE (Default Hyperparameters)\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Default hyperparameters\n",
                "default_hyperparams = {\n",
                "    'learning_rate': 3e-4,\n",
                "    'gamma': 0.99,\n",
                "    'gae_lambda': 0.95,\n",
                "    'clip_range': 0.2,\n",
                "    'ent_coef': 0.01,\n",
                "    'vf_coef': 0.5,\n",
                "    'n_steps': 512,\n",
                "    'batch_size': 64,\n",
                "    'n_epochs': 10,\n",
                "    'architecture': 'medium',\n",
                "    'activation': 'relu'\n",
                "}\n",
                "\n",
                "print(\"\\nDefault hyperparameters:\")\n",
                "for k, v in default_hyperparams.items():\n",
                "    print(f\"  {k}: {v}\")\n",
                "\n",
                "# Create environment config\n",
                "baseline_env_config = EnvConfig(\n",
                "    observation_mode='full_obs',\n",
                "    episode_length=TRAINING_CONFIG.episode_length,\n",
                "    switch_penalty=0.02,\n",
                "    collision_penalty=2.0\n",
                ")\n",
                "\n",
                "# Create vectorized environment\n",
                "set_all_seeds(GLOBAL_SEED)\n",
                "baseline_env = DummyVecEnv([make_env(spectrum_train, baseline_env_config, GLOBAL_SEED)])\n",
                "\n",
                "# Create and train baseline model\n",
                "print(f\"\\nTraining for {TRAINING_CONFIG.baseline_timesteps:,} timesteps...\")\n",
                "baseline_start_time = time.time()\n",
                "\n",
                "baseline_callback = MetricsCallback()\n",
                "baseline_model = create_ppo_model(baseline_env, default_hyperparams)\n",
                "baseline_model.learn(\n",
                "    total_timesteps=TRAINING_CONFIG.baseline_timesteps,\n",
                "    callback=baseline_callback,\n",
                "    progress_bar=True\n",
                ")\n",
                "\n",
                "baseline_train_time = time.time() - baseline_start_time\n",
                "print(f\"Training completed in {baseline_train_time:.1f} seconds\")\n",
                "\n",
                "# Evaluate baseline on test set\n",
                "print(\"\\nEvaluating on test set...\")\n",
                "eval_config = EnvConfig(\n",
                "    observation_mode='full_obs',\n",
                "    episode_length=TRAINING_CONFIG.episode_length,\n",
                "    deterministic_start=True,\n",
                "    switch_penalty=0.02,\n",
                "    collision_penalty=2.0\n",
                ")\n",
                "\n",
                "baseline_results = evaluate_model(\n",
                "    baseline_model, \n",
                "    spectrum_test, \n",
                "    eval_config,\n",
                "    n_episodes=TRAINING_CONFIG.ga_eval_episodes\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"BASELINE PPO RESULTS (Test Set)\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Mean Reward:     {baseline_results['mean_reward']:.2f} ± {baseline_results['std_reward']:.2f}\")\n",
                "print(f\"Success Rate:    {baseline_results['success_rate']:.2%}\")\n",
                "print(f\"Collision Rate:  {baseline_results['collision_rate']:.2%}\")\n",
                "print(f\"Switching Rate:  {baseline_results['switching_rate']:.2%}\")\n",
                "print(f\"Training Time:   {baseline_train_time:.1f}s\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Store baseline for comparison\n",
                "BASELINE_METRICS = baseline_results.copy()\n",
                "BASELINE_METRICS['training_time'] = baseline_train_time"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eb0441cc",
            "metadata": {},
            "source": [
                "## 6. Define GA Search Space and Encoding/Decoding\n",
                "\n",
                "Define the chromosome structure that encodes PPO hyperparameters. The GA will search over this space to find optimal configurations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dec38d35",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# GA SEARCH SPACE DEFINITION\n",
                "# ============================================================================\n",
                "\n",
                "@dataclass\n",
                "class HyperparameterSpace:\n",
                "    \"\"\"Defines the search space for each hyperparameter.\"\"\"\n",
                "    name: str\n",
                "    param_type: str  # 'continuous', 'discrete', 'categorical', 'log_uniform'\n",
                "    bounds: Tuple  # (min, max) for continuous/log_uniform, (options,) for discrete/categorical\n",
                "    \n",
                "# Define the complete search space\n",
                "SEARCH_SPACE = [\n",
                "    # PPO core hyperparameters\n",
                "    HyperparameterSpace('learning_rate', 'log_uniform', (1e-5, 3e-4)),\n",
                "    HyperparameterSpace('gamma', 'continuous', (0.90, 0.999)),\n",
                "    HyperparameterSpace('gae_lambda', 'continuous', (0.80, 0.99)),\n",
                "    HyperparameterSpace('clip_range', 'continuous', (0.1, 0.3)),\n",
                "    HyperparameterSpace('ent_coef', 'continuous', (0.0, 0.02)),\n",
                "    HyperparameterSpace('vf_coef', 'continuous', (0.2, 1.0)),\n",
                "    \n",
                "    # Discrete PPO parameters\n",
                "    HyperparameterSpace('n_steps', 'discrete', ([128, 256, 512, 1024],)),\n",
                "    HyperparameterSpace('batch_size', 'discrete', ([64, 128, 256],)),\n",
                "    HyperparameterSpace('n_epochs', 'discrete', ([5, 10, 15],)),\n",
                "    \n",
                "    # Network architecture\n",
                "    HyperparameterSpace('architecture', 'categorical', (['small', 'medium', 'large'],)),\n",
                "    HyperparameterSpace('activation', 'categorical', (['relu', 'tanh'],)),\n",
                "    \n",
                "    # Reward shaping parameters (environment-specific)\n",
                "    HyperparameterSpace('switch_penalty', 'continuous', (0.0, 0.05)),\n",
                "    HyperparameterSpace('collision_penalty', 'continuous', (1.0, 5.0)),\n",
                "]\n",
                "\n",
                "N_GENES = len(SEARCH_SPACE)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"GENETIC ALGORITHM SEARCH SPACE\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Total genes in chromosome: {N_GENES}\\n\")\n",
                "for i, hp in enumerate(SEARCH_SPACE):\n",
                "    if hp.param_type in ['continuous', 'log_uniform']:\n",
                "        print(f\"{i+1:2d}. {hp.name:20s} [{hp.param_type:12s}] range: {hp.bounds}\")\n",
                "    else:\n",
                "        print(f\"{i+1:2d}. {hp.name:20s} [{hp.param_type:12s}] options: {hp.bounds[0]}\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "add67076",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# CHROMOSOME ENCODING/DECODING FUNCTIONS\n",
                "# ============================================================================\n",
                "\n",
                "def create_random_chromosome() -> List[float]:\n",
                "    \"\"\"\n",
                "    Create a random chromosome (individual) encoding all hyperparameters.\n",
                "    \n",
                "    All genes are encoded as floats in [0, 1] range for uniform crossover/mutation.\n",
                "    Decoding maps these to actual hyperparameter values.\n",
                "    \n",
                "    Returns:\n",
                "        List of N_GENES floats in [0, 1]\n",
                "    \"\"\"\n",
                "    return [random.random() for _ in range(N_GENES)]\n",
                "\n",
                "\n",
                "def decode_chromosome(chromosome: List[float]) -> Dict[str, Any]:\n",
                "    \"\"\"\n",
                "    Decode a chromosome into actual hyperparameter values.\n",
                "    \n",
                "    Args:\n",
                "        chromosome: List of N_GENES floats in [0, 1]\n",
                "    \n",
                "    Returns:\n",
                "        Dictionary mapping hyperparameter names to decoded values\n",
                "    \"\"\"\n",
                "    hyperparams = {}\n",
                "    \n",
                "    for i, hp in enumerate(SEARCH_SPACE):\n",
                "        gene = np.clip(chromosome[i], 0.0, 1.0)\n",
                "        \n",
                "        if hp.param_type == 'continuous':\n",
                "            low, high = hp.bounds\n",
                "            hyperparams[hp.name] = low + gene * (high - low)\n",
                "            \n",
                "        elif hp.param_type == 'log_uniform':\n",
                "            low, high = hp.bounds\n",
                "            log_low, log_high = np.log10(low), np.log10(high)\n",
                "            hyperparams[hp.name] = 10 ** (log_low + gene * (log_high - log_low))\n",
                "            \n",
                "        elif hp.param_type == 'discrete':\n",
                "            options = hp.bounds[0]\n",
                "            idx = int(gene * len(options))\n",
                "            idx = min(idx, len(options) - 1)  # Ensure valid index\n",
                "            hyperparams[hp.name] = options[idx]\n",
                "            \n",
                "        elif hp.param_type == 'categorical':\n",
                "            options = hp.bounds[0]\n",
                "            idx = int(gene * len(options))\n",
                "            idx = min(idx, len(options) - 1)\n",
                "            hyperparams[hp.name] = options[idx]\n",
                "    \n",
                "    return hyperparams\n",
                "\n",
                "\n",
                "def encode_hyperparams(hyperparams: Dict[str, Any]) -> List[float]:\n",
                "    \"\"\"\n",
                "    Encode hyperparameters back into a chromosome.\n",
                "    \n",
                "    Args:\n",
                "        hyperparams: Dictionary of hyperparameter values\n",
                "    \n",
                "    Returns:\n",
                "        List of N_GENES floats in [0, 1]\n",
                "    \"\"\"\n",
                "    chromosome = []\n",
                "    \n",
                "    for hp in SEARCH_SPACE:\n",
                "        value = hyperparams[hp.name]\n",
                "        \n",
                "        if hp.param_type == 'continuous':\n",
                "            low, high = hp.bounds\n",
                "            gene = (value - low) / (high - low)\n",
                "            \n",
                "        elif hp.param_type == 'log_uniform':\n",
                "            low, high = hp.bounds\n",
                "            log_low, log_high = np.log10(low), np.log10(high)\n",
                "            gene = (np.log10(value) - log_low) / (log_high - log_low)\n",
                "            \n",
                "        elif hp.param_type in ['discrete', 'categorical']:\n",
                "            options = hp.bounds[0]\n",
                "            idx = options.index(value)\n",
                "            gene = (idx + 0.5) / len(options)\n",
                "        \n",
                "        chromosome.append(np.clip(gene, 0.0, 1.0))\n",
                "    \n",
                "    return chromosome\n",
                "\n",
                "\n",
                "def format_hyperparams(hyperparams: Dict[str, Any]) -> str:\n",
                "    \"\"\"Format hyperparameters for display.\"\"\"\n",
                "    lines = []\n",
                "    for k, v in hyperparams.items():\n",
                "        if isinstance(v, float):\n",
                "            if k == 'learning_rate':\n",
                "                lines.append(f\"  {k}: {v:.2e}\")\n",
                "            else:\n",
                "                lines.append(f\"  {k}: {v:.4f}\")\n",
                "        else:\n",
                "            lines.append(f\"  {k}: {v}\")\n",
                "    return \"\\n\".join(lines)\n",
                "\n",
                "\n",
                "# Test encoding/decoding\n",
                "print(\"Testing chromosome encoding/decoding...\")\n",
                "test_chromosome = create_random_chromosome()\n",
                "test_hyperparams = decode_chromosome(test_chromosome)\n",
                "print(\"\\nSample decoded hyperparameters:\")\n",
                "print(format_hyperparams(test_hyperparams))\n",
                "\n",
                "# Verify round-trip\n",
                "re_encoded = encode_hyperparams(test_hyperparams)\n",
                "re_decoded = decode_chromosome(re_encoded)\n",
                "print(\"\\n✓ Encoding/decoding working correctly\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "361f952e",
            "metadata": {},
            "source": [
                "## 7. Fitness Evaluation Function\n",
                "\n",
                "Define the fitness function that evaluates each candidate hyperparameter configuration. For each candidate, we train a PPO agent briefly and evaluate its performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f0d64014",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# FITNESS EVALUATION FUNCTION\n",
                "# ============================================================================\n",
                "\n",
                "# Global counter for tracking evaluations\n",
                "EVAL_COUNTER = {'count': 0}\n",
                "\n",
                "def evaluate_fitness(chromosome: List[float]) -> Tuple[float,]:\n",
                "    \"\"\"\n",
                "    Evaluate fitness of a chromosome by training and testing a PPO agent.\n",
                "    \n",
                "    Fitness formula:\n",
                "        fitness = success_rate - 2.5 * collision_rate - 0.1 * switching_rate\n",
                "    \n",
                "    This rewards high success (choosing free channels), penalizes collisions\n",
                "    heavily, and slightly penalizes frequent channel switching.\n",
                "    \n",
                "    Args:\n",
                "        chromosome: Encoded hyperparameters\n",
                "    \n",
                "    Returns:\n",
                "        Tuple with single fitness value (DEAP convention)\n",
                "    \"\"\"\n",
                "    EVAL_COUNTER['count'] += 1\n",
                "    eval_id = EVAL_COUNTER['count']\n",
                "    \n",
                "    try:\n",
                "        # Decode chromosome to hyperparameters\n",
                "        hyperparams = decode_chromosome(chromosome)\n",
                "        \n",
                "        # Create environment config with reward shaping parameters from chromosome\n",
                "        env_config = EnvConfig(\n",
                "            observation_mode='full_obs',\n",
                "            episode_length=TRAINING_CONFIG.episode_length,\n",
                "            switch_penalty=hyperparams['switch_penalty'],\n",
                "            collision_penalty=hyperparams['collision_penalty']\n",
                "        )\n",
                "        \n",
                "        # Create vectorized training environment\n",
                "        seed = GLOBAL_SEED + eval_id\n",
                "        set_all_seeds(seed)\n",
                "        train_env = DummyVecEnv([make_env(spectrum_train, env_config, seed)])\n",
                "        \n",
                "        # Create PPO model with decoded hyperparameters\n",
                "        model = create_ppo_model(train_env, hyperparams, seed=seed)\n",
                "        \n",
                "        # Train for limited timesteps\n",
                "        model.learn(\n",
                "            total_timesteps=TRAINING_CONFIG.ga_training_timesteps,\n",
                "            progress_bar=False\n",
                "        )\n",
                "        \n",
                "        # Evaluate on test data\n",
                "        eval_config = EnvConfig(\n",
                "            observation_mode='full_obs',\n",
                "            episode_length=TRAINING_CONFIG.episode_length,\n",
                "            deterministic_start=True,\n",
                "            switch_penalty=hyperparams['switch_penalty'],\n",
                "            collision_penalty=hyperparams['collision_penalty']\n",
                "        )\n",
                "        \n",
                "        results = evaluate_model(\n",
                "            model,\n",
                "            spectrum_test,\n",
                "            eval_config,\n",
                "            n_episodes=TRAINING_CONFIG.ga_eval_episodes,\n",
                "            deterministic=True\n",
                "        )\n",
                "        \n",
                "        # Compute fitness score\n",
                "        fitness = (\n",
                "            results['success_rate'] \n",
                "            - 2.5 * results['collision_rate'] \n",
                "            - 0.1 * results['switching_rate']\n",
                "        )\n",
                "        \n",
                "        # Clean up\n",
                "        train_env.close()\n",
                "        del model\n",
                "        \n",
                "        # Print progress indicator\n",
                "        print(f\"  [{eval_id:3d}] Fitness: {fitness:+.4f} | \"\n",
                "              f\"Success: {results['success_rate']:.2%} | \"\n",
                "              f\"Collision: {results['collision_rate']:.2%}\")\n",
                "        \n",
                "        return (fitness,)\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"  [{eval_id:3d}] ERROR: {str(e)[:50]}... → Fitness: -10.0\")\n",
                "        return (-10.0,)  # Large negative fitness for failed evaluations\n",
                "\n",
                "\n",
                "print(\"✓ Fitness evaluation function defined\")\n",
                "print(f\"\\nFitness formula: success_rate - 2.5 × collision_rate - 0.1 × switching_rate\")\n",
                "print(f\"  → Rewards choosing free channels\")\n",
                "print(f\"  → Heavily penalizes collisions with Primary Users\")\n",
                "print(f\"  → Slightly penalizes frequent channel switching\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b4cb92bc",
            "metadata": {},
            "source": [
                "## 8. Run GA Optimization Loop\n",
                "\n",
                "Execute the Genetic Algorithm to find optimal PPO hyperparameters. The GA uses tournament selection, uniform crossover, and Gaussian mutation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "139b813c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# SETUP DEAP GENETIC ALGORITHM\n",
                "# ============================================================================\n",
                "\n",
                "# Clear any existing DEAP classes (for notebook re-runs)\n",
                "if 'FitnessMax' in dir(creator):\n",
                "    del creator.FitnessMax\n",
                "if 'Individual' in dir(creator):\n",
                "    del creator.Individual\n",
                "\n",
                "# Create fitness and individual classes\n",
                "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))  # Maximize fitness\n",
                "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
                "\n",
                "# Create toolbox with genetic operators\n",
                "toolbox = base.Toolbox()\n",
                "\n",
                "# Gene initialization (random float in [0, 1])\n",
                "toolbox.register(\"attr_gene\", random.random)\n",
                "\n",
                "# Individual and population initialization\n",
                "toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
                "                 toolbox.attr_gene, n=N_GENES)\n",
                "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
                "\n",
                "# Genetic operators\n",
                "toolbox.register(\"evaluate\", evaluate_fitness)\n",
                "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
                "toolbox.register(\"mate\", tools.cxUniform, indpb=0.5)  # Uniform crossover\n",
                "\n",
                "def mutate_gaussian(individual, mu=0, sigma=0.1, indpb=0.2):\n",
                "    \"\"\"\n",
                "    Gaussian mutation for continuous genes with discrete gene handling.\n",
                "    \n",
                "    Args:\n",
                "        individual: Chromosome to mutate\n",
                "        mu: Mean of Gaussian noise\n",
                "        sigma: Standard deviation of Gaussian noise\n",
                "        indpb: Probability of mutating each gene\n",
                "    \"\"\"\n",
                "    for i in range(len(individual)):\n",
                "        if random.random() < indpb:\n",
                "            hp = SEARCH_SPACE[i]\n",
                "            \n",
                "            if hp.param_type in ['discrete', 'categorical']:\n",
                "                # For discrete/categorical: random resample\n",
                "                individual[i] = random.random()\n",
                "            else:\n",
                "                # For continuous: Gaussian mutation with bounds clipping\n",
                "                individual[i] += random.gauss(mu, sigma)\n",
                "                individual[i] = np.clip(individual[i], 0.0, 1.0)\n",
                "    \n",
                "    return (individual,)\n",
                "\n",
                "toolbox.register(\"mutate\", mutate_gaussian, sigma=0.15, indpb=0.25)\n",
                "\n",
                "\n",
                "def print_leaderboard(population: List, generation: int, top_n: int = 5):\n",
                "    \"\"\"Print leaderboard of top individuals.\"\"\"\n",
                "    # Sort by fitness (descending)\n",
                "    sorted_pop = sorted(population, key=lambda x: x.fitness.values[0], reverse=True)\n",
                "    \n",
                "    print(f\"\\n{'═' * 80}\")\n",
                "    print(f\"GENERATION {generation} LEADERBOARD (Top {top_n})\")\n",
                "    print(f\"{'═' * 80}\")\n",
                "    print(f\"{'Rank':<6}{'Fitness':<12}{'Success%':<10}{'LR':<12}{'γ':<8}{'n_steps':<10}{'Arch':<10}\")\n",
                "    print(f\"{'─' * 80}\")\n",
                "    \n",
                "    for rank, ind in enumerate(sorted_pop[:top_n], 1):\n",
                "        hp = decode_chromosome(ind)\n",
                "        fitness = ind.fitness.values[0]\n",
                "        # Estimate success rate from fitness (rough inverse)\n",
                "        est_success = fitness + 0.1  # Rough estimate\n",
                "        print(f\"{rank:<6}{fitness:+.4f}{'':4}{est_success:.1%}{'':4}\"\n",
                "              f\"{hp['learning_rate']:.2e}{'':2}{hp['gamma']:.3f}{'':3}\"\n",
                "              f\"{hp['n_steps']:<10}{hp['architecture']:<10}\")\n",
                "    \n",
                "    print(f\"{'═' * 80}\\n\")\n",
                "\n",
                "\n",
                "print(\"✓ DEAP Genetic Algorithm configured\")\n",
                "print(f\"\\nGA Settings:\")\n",
                "print(f\"  Population size:  {TRAINING_CONFIG.ga_population_size}\")\n",
                "print(f\"  Generations:      {TRAINING_CONFIG.ga_generations}\")\n",
                "print(f\"  Selection:        Tournament (size=3)\")\n",
                "print(f\"  Crossover:        Uniform (prob={TRAINING_CONFIG.ga_crossover_prob})\")\n",
                "print(f\"  Mutation:         Gaussian (prob={TRAINING_CONFIG.ga_mutation_prob})\")\n",
                "print(f\"  Elitism:          Top {TRAINING_CONFIG.ga_elitism} individuals preserved\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6c21c2b7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# RUN GENETIC ALGORITHM OPTIMIZATION\n",
                "# ============================================================================\n",
                "\n",
                "print(\"=\" * 80)\n",
                "print(\"STARTING GENETIC ALGORITHM OPTIMIZATION\")\n",
                "print(\"=\" * 80)\n",
                "print(f\"\\nEstimated time: ~{TRAINING_CONFIG.ga_population_size * TRAINING_CONFIG.ga_generations * 1.5:.0f} minutes\")\n",
                "print(\"(Actual time depends on hardware and training budget)\\n\")\n",
                "\n",
                "# Reset evaluation counter\n",
                "EVAL_COUNTER['count'] = 0\n",
                "\n",
                "# Set seed for reproducibility\n",
                "set_all_seeds(GLOBAL_SEED)\n",
                "random.seed(GLOBAL_SEED)\n",
                "\n",
                "# Initialize population\n",
                "population = toolbox.population(n=TRAINING_CONFIG.ga_population_size)\n",
                "\n",
                "# Statistics tracking\n",
                "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
                "stats.register(\"avg\", np.mean)\n",
                "stats.register(\"std\", np.std)\n",
                "stats.register(\"min\", np.min)\n",
                "stats.register(\"max\", np.max)\n",
                "\n",
                "# Hall of Fame (keeps best individuals)\n",
                "hof = tools.HallOfFame(TRAINING_CONFIG.ga_elitism)\n",
                "\n",
                "# Logbook for tracking evolution\n",
                "logbook = tools.Logbook()\n",
                "logbook.header = ['gen', 'nevals', 'avg', 'std', 'min', 'max']\n",
                "\n",
                "# GA start time\n",
                "ga_start_time = time.time()\n",
                "\n",
                "# ============================================================================\n",
                "# EVOLUTION LOOP\n",
                "# ============================================================================\n",
                "\n",
                "print(\"Evaluating initial population...\")\n",
                "print(\"─\" * 80)\n",
                "\n",
                "# Evaluate initial population\n",
                "fitnesses = list(map(toolbox.evaluate, population))\n",
                "for ind, fit in zip(population, fitnesses):\n",
                "    ind.fitness.values = fit\n",
                "\n",
                "# Update hall of fame\n",
                "hof.update(population)\n",
                "\n",
                "# Record initial stats\n",
                "record = stats.compile(population)\n",
                "logbook.record(gen=0, nevals=len(population), **record)\n",
                "print_leaderboard(population, 0)\n",
                "\n",
                "# Evolution loop\n",
                "for gen in range(1, TRAINING_CONFIG.ga_generations + 1):\n",
                "    print(f\"\\n{'═' * 80}\")\n",
                "    print(f\"GENERATION {gen}/{TRAINING_CONFIG.ga_generations}\")\n",
                "    print(f\"{'═' * 80}\")\n",
                "    \n",
                "    # Select parents\n",
                "    offspring = toolbox.select(population, len(population) - TRAINING_CONFIG.ga_elitism)\n",
                "    offspring = list(map(toolbox.clone, offspring))\n",
                "    \n",
                "    # Apply crossover\n",
                "    for i in range(0, len(offspring) - 1, 2):\n",
                "        if random.random() < TRAINING_CONFIG.ga_crossover_prob:\n",
                "            toolbox.mate(offspring[i], offspring[i + 1])\n",
                "            del offspring[i].fitness.values\n",
                "            del offspring[i + 1].fitness.values\n",
                "    \n",
                "    # Apply mutation\n",
                "    for mutant in offspring:\n",
                "        if random.random() < TRAINING_CONFIG.ga_mutation_prob:\n",
                "            toolbox.mutate(mutant)\n",
                "            del mutant.fitness.values\n",
                "    \n",
                "    # Evaluate individuals with invalid fitness\n",
                "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
                "    print(f\"Evaluating {len(invalid_ind)} new individuals...\")\n",
                "    print(\"─\" * 80)\n",
                "    \n",
                "    fitnesses = list(map(toolbox.evaluate, invalid_ind))\n",
                "    for ind, fit in zip(invalid_ind, fitnesses):\n",
                "        ind.fitness.values = fit\n",
                "    \n",
                "    # Elitism: add back best individuals from previous generation\n",
                "    elite = tools.selBest(population, TRAINING_CONFIG.ga_elitism)\n",
                "    offspring.extend(elite)\n",
                "    \n",
                "    # Replace population\n",
                "    population[:] = offspring\n",
                "    \n",
                "    # Update hall of fame\n",
                "    hof.update(population)\n",
                "    \n",
                "    # Record stats\n",
                "    record = stats.compile(population)\n",
                "    logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
                "    \n",
                "    # Print leaderboard\n",
                "    print_leaderboard(population, gen)\n",
                "    \n",
                "    # Print generation summary\n",
                "    print(f\"Generation {gen} Statistics:\")\n",
                "    print(f\"  Avg Fitness: {record['avg']:+.4f} ± {record['std']:.4f}\")\n",
                "    print(f\"  Best: {record['max']:+.4f} | Worst: {record['min']:+.4f}\")\n",
                "\n",
                "ga_total_time = time.time() - ga_start_time\n",
                "\n",
                "print(\"\\n\" + \"=\" * 80)\n",
                "print(\"GENETIC ALGORITHM COMPLETED\")\n",
                "print(\"=\" * 80)\n",
                "print(f\"Total time: {ga_total_time / 60:.1f} minutes\")\n",
                "print(f\"Total evaluations: {EVAL_COUNTER['count']}\")\n",
                "\n",
                "# Get best individual\n",
                "best_individual = hof[0]\n",
                "best_hyperparams = decode_chromosome(best_individual)\n",
                "best_fitness = best_individual.fitness.values[0]\n",
                "\n",
                "print(f\"\\nBest Fitness: {best_fitness:+.4f}\")\n",
                "print(\"\\nBest Hyperparameters:\")\n",
                "print(format_hyperparams(best_hyperparams))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5098c031",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# PLOT GA EVOLUTION HISTORY\n",
                "# ============================================================================\n",
                "\n",
                "# Extract evolution data from logbook\n",
                "gen_nums = logbook.select(\"gen\")\n",
                "avg_fitness = logbook.select(\"avg\")\n",
                "max_fitness = logbook.select(\"max\")\n",
                "min_fitness = logbook.select(\"min\")\n",
                "std_fitness = logbook.select(\"std\")\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Plot 1: Fitness over generations\n",
                "ax1 = axes[0]\n",
                "ax1.plot(gen_nums, max_fitness, 'g-', linewidth=2, label='Best', marker='o')\n",
                "ax1.plot(gen_nums, avg_fitness, 'b-', linewidth=2, label='Average', marker='s')\n",
                "ax1.fill_between(gen_nums, \n",
                "                  np.array(avg_fitness) - np.array(std_fitness),\n",
                "                  np.array(avg_fitness) + np.array(std_fitness),\n",
                "                  alpha=0.2, color='blue')\n",
                "ax1.plot(gen_nums, min_fitness, 'r--', linewidth=1, label='Worst', alpha=0.7)\n",
                "ax1.set_xlabel('Generation', fontsize=12)\n",
                "ax1.set_ylabel('Fitness Score', fontsize=12)\n",
                "ax1.set_title('GA Evolution: Fitness Over Generations', fontsize=14)\n",
                "ax1.legend(loc='best')\n",
                "ax1.grid(True, alpha=0.3)\n",
                "ax1.set_xticks(gen_nums)\n",
                "\n",
                "# Plot 2: Improvement from baseline\n",
                "ax2 = axes[1]\n",
                "baseline_fitness = (BASELINE_METRICS['success_rate'] \n",
                "                   - 2.5 * BASELINE_METRICS['collision_rate'] \n",
                "                   - 0.1 * BASELINE_METRICS['switching_rate'])\n",
                "\n",
                "improvements = np.array(max_fitness) - baseline_fitness\n",
                "colors = ['green' if x > 0 else 'red' for x in improvements]\n",
                "bars = ax2.bar(gen_nums, improvements, color=colors, alpha=0.7, edgecolor='black')\n",
                "ax2.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
                "ax2.set_xlabel('Generation', fontsize=12)\n",
                "ax2.set_ylabel('Improvement over Baseline', fontsize=12)\n",
                "ax2.set_title('Best Individual Improvement vs Default PPO', fontsize=14)\n",
                "ax2.set_xticks(gen_nums)\n",
                "ax2.grid(True, alpha=0.3, axis='y')\n",
                "\n",
                "# Add value labels on bars\n",
                "for bar, val in zip(bars, improvements):\n",
                "    height = bar.get_height()\n",
                "    ax2.annotate(f'{val:+.3f}',\n",
                "                 xy=(bar.get_x() + bar.get_width() / 2, height),\n",
                "                 xytext=(0, 3 if height >= 0 else -15),\n",
                "                 textcoords=\"offset points\",\n",
                "                 ha='center', va='bottom' if height >= 0 else 'top',\n",
                "                 fontsize=9)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(RESULTS_DIR / 'ga_evolution.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n✓ Evolution plot saved to: {RESULTS_DIR / 'ga_evolution.png'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7ce6d3c8",
            "metadata": {},
            "source": [
                "## 9. Train Final PPO with Best Parameters\n",
                "\n",
                "Train the final PPO agent using the best hyperparameters found by the GA. This training uses a larger timestep budget for better performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59025efc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# TRAIN FINAL PPO MODEL WITH BEST HYPERPARAMETERS\n",
                "# ============================================================================\n",
                "\n",
                "print(\"=\" * 80)\n",
                "print(\"TRAINING FINAL PPO MODEL WITH GA-OPTIMIZED HYPERPARAMETERS\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "print(\"\\nBest hyperparameters from GA:\")\n",
                "print(format_hyperparams(best_hyperparams))\n",
                "\n",
                "# Create environment config with best reward shaping parameters\n",
                "final_env_config = EnvConfig(\n",
                "    observation_mode='full_obs',\n",
                "    episode_length=TRAINING_CONFIG.episode_length,\n",
                "    switch_penalty=best_hyperparams['switch_penalty'],\n",
                "    collision_penalty=best_hyperparams['collision_penalty']\n",
                ")\n",
                "\n",
                "# Create vectorized training environment\n",
                "set_all_seeds(GLOBAL_SEED)\n",
                "final_train_env = DummyVecEnv([make_env(spectrum_train, final_env_config, GLOBAL_SEED)])\n",
                "\n",
                "# Create final model with best hyperparameters\n",
                "print(f\"\\nCreating PPO model with optimized configuration...\")\n",
                "final_model = create_ppo_model(final_train_env, best_hyperparams, seed=GLOBAL_SEED)\n",
                "\n",
                "# Training callback to track progress\n",
                "final_callback = MetricsCallback()\n",
                "\n",
                "# Train for extended duration\n",
                "print(f\"\\nTraining for {TRAINING_CONFIG.final_training_timesteps:,} timesteps...\")\n",
                "print(\"This may take a while...\\n\")\n",
                "\n",
                "final_start_time = time.time()\n",
                "\n",
                "final_model.learn(\n",
                "    total_timesteps=TRAINING_CONFIG.final_training_timesteps,\n",
                "    callback=final_callback,\n",
                "    progress_bar=True\n",
                ")\n",
                "\n",
                "final_train_time = time.time() - final_start_time\n",
                "\n",
                "print(f\"\\n✓ Training completed in {final_train_time / 60:.1f} minutes\")\n",
                "print(f\"  Total episodes during training: ~{len(final_callback.episode_rewards)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9757ae40",
            "metadata": {},
            "source": [
                "## 10. Final Evaluation and Visualization\n",
                "\n",
                "Comprehensive evaluation of the final GA-optimized PPO model on the test dataset, with comparison to baseline performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "79e54869",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# COMPREHENSIVE FINAL EVALUATION\n",
                "# ============================================================================\n",
                "\n",
                "print(\"=\" * 80)\n",
                "print(\"FINAL EVALUATION ON TEST SET\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "# Evaluation config\n",
                "eval_config = EnvConfig(\n",
                "    observation_mode='full_obs',\n",
                "    episode_length=TRAINING_CONFIG.episode_length,\n",
                "    deterministic_start=True,\n",
                "    switch_penalty=best_hyperparams['switch_penalty'],\n",
                "    collision_penalty=best_hyperparams['collision_penalty']\n",
                ")\n",
                "\n",
                "# Run comprehensive evaluation\n",
                "print(f\"\\nRunning {TRAINING_CONFIG.final_eval_episodes} evaluation episodes...\")\n",
                "\n",
                "final_results = evaluate_model(\n",
                "    final_model,\n",
                "    spectrum_test,\n",
                "    eval_config,\n",
                "    n_episodes=TRAINING_CONFIG.final_eval_episodes,\n",
                "    deterministic=True\n",
                ")\n",
                "\n",
                "# Also collect episode-level data for visualization\n",
                "eval_env = SpectrumEnvFromDataset(spectrum_test, eval_config, seed=GLOBAL_SEED + 2000)\n",
                "episode_rewards = []\n",
                "episode_success_rates = []\n",
                "episode_collision_rates = []\n",
                "episode_details = []\n",
                "\n",
                "for ep in range(TRAINING_CONFIG.final_eval_episodes):\n",
                "    start_idx = (ep * eval_config.episode_length) % max(1, spectrum_test.shape[0] - eval_config.episode_length - 20)\n",
                "    obs, info = eval_env.reset(options={'start_index': start_idx})\n",
                "    done = False\n",
                "    \n",
                "    ep_actions = []\n",
                "    ep_collisions = []\n",
                "    \n",
                "    while not done:\n",
                "        action, _ = final_model.predict(obs, deterministic=True)\n",
                "        obs, reward, terminated, truncated, info = eval_env.step(int(action))\n",
                "        ep_actions.append(int(action))\n",
                "        ep_collisions.append(info['is_collision'])\n",
                "        done = terminated or truncated\n",
                "    \n",
                "    metrics = eval_env.get_episode_metrics()\n",
                "    episode_rewards.append(metrics['total_reward'])\n",
                "    episode_success_rates.append(metrics['success_rate'])\n",
                "    episode_collision_rates.append(metrics['collision_rate'])\n",
                "    episode_details.append({\n",
                "        'actions': ep_actions,\n",
                "        'collisions': ep_collisions\n",
                "    })\n",
                "\n",
                "# Print results\n",
                "print(\"\\n\" + \"=\" * 80)\n",
                "print(\"FINAL MODEL PERFORMANCE (GA-Optimized PPO)\")\n",
                "print(\"=\" * 80)\n",
                "print(f\"\\nTest Episodes:     {TRAINING_CONFIG.final_eval_episodes}\")\n",
                "print(f\"Episode Length:    {TRAINING_CONFIG.episode_length}\")\n",
                "print(f\"\\nMetrics:\")\n",
                "print(f\"  Mean Reward:     {final_results['mean_reward']:.2f} ± {final_results['std_reward']:.2f}\")\n",
                "print(f\"  Success Rate:    {final_results['success_rate']:.2%}\")\n",
                "print(f\"  Collision Rate:  {final_results['collision_rate']:.2%}\")\n",
                "print(f\"  Switching Rate:  {final_results['switching_rate']:.2%}\")\n",
                "print(f\"\\nTraining Time:     {final_train_time / 60:.1f} minutes\")\n",
                "print(f\"Total Timesteps:   {TRAINING_CONFIG.final_training_timesteps:,}\")\n",
                "\n",
                "# Comparison with baseline\n",
                "print(\"\\n\" + \"─\" * 80)\n",
                "print(\"COMPARISON WITH BASELINE (Default PPO)\")\n",
                "print(\"─\" * 80)\n",
                "print(f\"{'Metric':<20}{'Baseline':<15}{'GA-Optimized':<15}{'Improvement':<15}\")\n",
                "print(\"─\" * 80)\n",
                "\n",
                "metrics_comparison = [\n",
                "    ('Mean Reward', BASELINE_METRICS['mean_reward'], final_results['mean_reward']),\n",
                "    ('Success Rate', BASELINE_METRICS['success_rate'], final_results['success_rate']),\n",
                "    ('Collision Rate', BASELINE_METRICS['collision_rate'], final_results['collision_rate']),\n",
                "    ('Switching Rate', BASELINE_METRICS['switching_rate'], final_results['switching_rate']),\n",
                "]\n",
                "\n",
                "for metric_name, baseline_val, final_val in metrics_comparison:\n",
                "    if 'Rate' in metric_name:\n",
                "        diff = final_val - baseline_val\n",
                "        improvement = f\"{diff:+.2%}\"\n",
                "        baseline_str = f\"{baseline_val:.2%}\"\n",
                "        final_str = f\"{final_val:.2%}\"\n",
                "    else:\n",
                "        diff = final_val - baseline_val\n",
                "        improvement = f\"{diff:+.2f}\"\n",
                "        baseline_str = f\"{baseline_val:.2f}\"\n",
                "        final_str = f\"{final_val:.2f}\"\n",
                "    \n",
                "    # Add indicator for improvement direction\n",
                "    if 'Collision' in metric_name or 'Switching' in metric_name:\n",
                "        # Lower is better for these metrics\n",
                "        indicator = \"✓\" if diff < 0 else \"✗\"\n",
                "    else:\n",
                "        indicator = \"✓\" if diff > 0 else \"✗\"\n",
                "    \n",
                "    print(f\"{metric_name:<20}{baseline_str:<15}{final_str:<15}{improvement} {indicator}\")\n",
                "\n",
                "print(\"=\" * 80)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d1a824d1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# VISUALIZATION PLOTS\n",
                "# ============================================================================\n",
                "\n",
                "fig = plt.figure(figsize=(16, 12))\n",
                "\n",
                "# 1. Training Reward Curve\n",
                "ax1 = fig.add_subplot(2, 3, 1)\n",
                "if len(final_callback.episode_rewards) > 0:\n",
                "    window = max(1, len(final_callback.episode_rewards) // 50)\n",
                "    rewards_array = np.array(final_callback.episode_rewards)\n",
                "    rolling_mean = np.convolve(rewards_array, np.ones(window)/window, mode='valid')\n",
                "    ax1.plot(rolling_mean, color='steelblue', linewidth=1.5)\n",
                "    ax1.fill_between(range(len(rolling_mean)), rolling_mean, alpha=0.3, color='steelblue')\n",
                "    ax1.set_xlabel('Episode')\n",
                "    ax1.set_ylabel('Reward')\n",
                "    ax1.set_title('Training Reward Curve (Rolling Average)')\n",
                "    ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# 2. Episode Rewards Distribution\n",
                "ax2 = fig.add_subplot(2, 3, 2)\n",
                "ax2.hist(episode_rewards, bins=20, color='steelblue', alpha=0.7, edgecolor='black')\n",
                "ax2.axvline(x=np.mean(episode_rewards), color='red', linestyle='--', linewidth=2,\n",
                "            label=f'Mean: {np.mean(episode_rewards):.1f}')\n",
                "ax2.set_xlabel('Episode Reward')\n",
                "ax2.set_ylabel('Frequency')\n",
                "ax2.set_title('Evaluation Episode Reward Distribution')\n",
                "ax2.legend()\n",
                "ax2.grid(True, alpha=0.3, axis='y')\n",
                "\n",
                "# 3. Success vs Collision Rate per Episode\n",
                "ax3 = fig.add_subplot(2, 3, 3)\n",
                "episodes = range(len(episode_success_rates))\n",
                "ax3.plot(episodes, episode_success_rates, 'g-', linewidth=1.5, label='Success Rate', alpha=0.8)\n",
                "ax3.plot(episodes, episode_collision_rates, 'r-', linewidth=1.5, label='Collision Rate', alpha=0.8)\n",
                "ax3.fill_between(episodes, episode_success_rates, alpha=0.2, color='green')\n",
                "ax3.fill_between(episodes, episode_collision_rates, alpha=0.2, color='red')\n",
                "ax3.set_xlabel('Episode')\n",
                "ax3.set_ylabel('Rate')\n",
                "ax3.set_title('Success vs Collision Rate per Episode')\n",
                "ax3.legend()\n",
                "ax3.grid(True, alpha=0.3)\n",
                "ax3.set_ylim(0, 1)\n",
                "\n",
                "# 4. Channel Selection Distribution\n",
                "ax4 = fig.add_subplot(2, 3, 4)\n",
                "channel_counts = final_results['channel_selections']\n",
                "colors = plt.cm.viridis(np.linspace(0, 1, N_CHANNELS))\n",
                "bars = ax4.bar(range(N_CHANNELS), channel_counts, color=colors, edgecolor='black', alpha=0.8)\n",
                "ax4.set_xlabel('Channel Index')\n",
                "ax4.set_ylabel('Selection Count')\n",
                "ax4.set_title('Channel Selection Distribution (Test Set)')\n",
                "ax4.set_xticks(range(N_CHANNELS))\n",
                "ax4.grid(True, alpha=0.3, axis='y')\n",
                "\n",
                "# Highlight most/least selected channels\n",
                "max_ch = np.argmax(channel_counts)\n",
                "min_ch = np.argmin(channel_counts)\n",
                "bars[max_ch].set_edgecolor('green')\n",
                "bars[max_ch].set_linewidth(3)\n",
                "bars[min_ch].set_edgecolor('red')\n",
                "bars[min_ch].set_linewidth(3)\n",
                "\n",
                "# 5. Performance Comparison Bar Chart\n",
                "ax5 = fig.add_subplot(2, 3, 5)\n",
                "metrics_names = ['Success\\nRate', 'Collision\\nRate', 'Switching\\nRate']\n",
                "baseline_vals = [BASELINE_METRICS['success_rate'], \n",
                "                 BASELINE_METRICS['collision_rate'],\n",
                "                 BASELINE_METRICS['switching_rate']]\n",
                "final_vals = [final_results['success_rate'],\n",
                "              final_results['collision_rate'],\n",
                "              final_results['switching_rate']]\n",
                "random_vals = [random_baseline['mean_success_rate'],\n",
                "               random_baseline['mean_collision_rate'],\n",
                "               random_baseline['mean_switching_rate']]\n",
                "\n",
                "x = np.arange(len(metrics_names))\n",
                "width = 0.25\n",
                "\n",
                "bars1 = ax5.bar(x - width, random_vals, width, label='Random', color='gray', alpha=0.7)\n",
                "bars2 = ax5.bar(x, baseline_vals, width, label='Default PPO', color='steelblue', alpha=0.7)\n",
                "bars3 = ax5.bar(x + width, final_vals, width, label='GA-Optimized', color='green', alpha=0.7)\n",
                "\n",
                "ax5.set_ylabel('Rate')\n",
                "ax5.set_title('Performance Comparison')\n",
                "ax5.set_xticks(x)\n",
                "ax5.set_xticklabels(metrics_names)\n",
                "ax5.legend()\n",
                "ax5.grid(True, alpha=0.3, axis='y')\n",
                "ax5.set_ylim(0, 1)\n",
                "\n",
                "# 6. Spectrum Utilization Heatmap (sample episode)\n",
                "ax6 = fig.add_subplot(2, 3, 6)\n",
                "if len(episode_details) > 0:\n",
                "    sample_ep = episode_details[0]\n",
                "    actions = sample_ep['actions'][:100]  # First 100 steps\n",
                "    collisions = sample_ep['collisions'][:100]\n",
                "    \n",
                "    # Create action heatmap\n",
                "    action_matrix = np.zeros((N_CHANNELS, len(actions)))\n",
                "    for t, (a, c) in enumerate(zip(actions, collisions)):\n",
                "        action_matrix[a, t] = 2 if c else 1  # 2=collision, 1=success\n",
                "    \n",
                "    im = ax6.imshow(action_matrix, aspect='auto', cmap='RdYlGn_r',\n",
                "                    interpolation='nearest', vmin=0, vmax=2)\n",
                "    ax6.set_xlabel('Timestep')\n",
                "    ax6.set_ylabel('Channel')\n",
                "    ax6.set_title('Channel Selection Heatmap (Sample Episode)')\n",
                "    cbar = plt.colorbar(im, ax=ax6, ticks=[0, 1, 2])\n",
                "    cbar.set_ticklabels(['Not Selected', 'Success', 'Collision'])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(RESULTS_DIR / 'final_evaluation.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n✓ Evaluation plots saved to: {RESULTS_DIR / 'final_evaluation.png'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1f9c2c2d",
            "metadata": {},
            "source": [
                "## 11. Save Model and Results Artifacts\n",
                "\n",
                "Save the trained PPO model and complete results to disk for later use and documentation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "acee5284",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# SAVE MODEL AND RESULTS\n",
                "# ============================================================================\n",
                "\n",
                "print(\"=\" * 80)\n",
                "print(\"SAVING ARTIFACTS\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "# 1. Save the trained PPO model\n",
                "model_path = MODELS_DIR / \"best_ppo_spectrum.zip\"\n",
                "final_model.save(str(model_path))\n",
                "print(f\"\\n✓ Model saved to: {model_path}\")\n",
                "\n",
                "# 2. Prepare comprehensive results dictionary\n",
                "results_dict = {\n",
                "    \"experiment_info\": {\n",
                "        \"name\": \"GA-Optimized PPO for 6G Cognitive Radio DSA\",\n",
                "        \"date\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
                "        \"global_seed\": GLOBAL_SEED,\n",
                "        \"training_config\": asdict(TRAINING_CONFIG)\n",
                "    },\n",
                "    \n",
                "    \"dataset_info\": {\n",
                "        \"train_shape\": list(spectrum_train.shape),\n",
                "        \"test_shape\": list(spectrum_test.shape),\n",
                "        \"n_channels\": N_CHANNELS,\n",
                "        \"train_occupancy_rate\": float(np.mean(spectrum_train)),\n",
                "        \"test_occupancy_rate\": float(np.mean(spectrum_test))\n",
                "    },\n",
                "    \n",
                "    \"ga_results\": {\n",
                "        \"population_size\": TRAINING_CONFIG.ga_population_size,\n",
                "        \"generations\": TRAINING_CONFIG.ga_generations,\n",
                "        \"total_evaluations\": EVAL_COUNTER['count'],\n",
                "        \"ga_runtime_seconds\": ga_total_time,\n",
                "        \"best_fitness\": float(best_fitness),\n",
                "        \"evolution_history\": {\n",
                "            \"generations\": list(gen_nums),\n",
                "            \"avg_fitness\": [float(x) for x in avg_fitness],\n",
                "            \"max_fitness\": [float(x) for x in max_fitness],\n",
                "            \"min_fitness\": [float(x) for x in min_fitness]\n",
                "        }\n",
                "    },\n",
                "    \n",
                "    \"best_hyperparameters\": {\n",
                "        k: float(v) if isinstance(v, (np.floating, float)) else v \n",
                "        for k, v in best_hyperparams.items()\n",
                "    },\n",
                "    \n",
                "    \"baseline_results\": {\n",
                "        \"hyperparameters\": default_hyperparams,\n",
                "        \"training_timesteps\": TRAINING_CONFIG.baseline_timesteps,\n",
                "        \"training_time_seconds\": baseline_train_time,\n",
                "        \"test_metrics\": {\n",
                "            \"mean_reward\": float(BASELINE_METRICS['mean_reward']),\n",
                "            \"std_reward\": float(BASELINE_METRICS['std_reward']),\n",
                "            \"success_rate\": float(BASELINE_METRICS['success_rate']),\n",
                "            \"collision_rate\": float(BASELINE_METRICS['collision_rate']),\n",
                "            \"switching_rate\": float(BASELINE_METRICS['switching_rate'])\n",
                "        }\n",
                "    },\n",
                "    \n",
                "    \"final_model_results\": {\n",
                "        \"training_timesteps\": TRAINING_CONFIG.final_training_timesteps,\n",
                "        \"training_time_seconds\": final_train_time,\n",
                "        \"test_episodes\": TRAINING_CONFIG.final_eval_episodes,\n",
                "        \"test_metrics\": {\n",
                "            \"mean_reward\": float(final_results['mean_reward']),\n",
                "            \"std_reward\": float(final_results['std_reward']),\n",
                "            \"success_rate\": float(final_results['success_rate']),\n",
                "            \"collision_rate\": float(final_results['collision_rate']),\n",
                "            \"switching_rate\": float(final_results['switching_rate'])\n",
                "        },\n",
                "        \"channel_selections\": final_results['channel_selections'].tolist()\n",
                "    },\n",
                "    \n",
                "    \"random_baseline\": {\n",
                "        \"mean_reward\": float(random_baseline['mean_reward']),\n",
                "        \"success_rate\": float(random_baseline['mean_success_rate']),\n",
                "        \"collision_rate\": float(random_baseline['mean_collision_rate']),\n",
                "        \"switching_rate\": float(random_baseline['mean_switching_rate'])\n",
                "    },\n",
                "    \n",
                "    \"improvement_over_baseline\": {\n",
                "        \"success_rate_delta\": float(final_results['success_rate'] - BASELINE_METRICS['success_rate']),\n",
                "        \"collision_rate_delta\": float(final_results['collision_rate'] - BASELINE_METRICS['collision_rate']),\n",
                "        \"switching_rate_delta\": float(final_results['switching_rate'] - BASELINE_METRICS['switching_rate']),\n",
                "        \"mean_reward_delta\": float(final_results['mean_reward'] - BASELINE_METRICS['mean_reward'])\n",
                "    }\n",
                "}\n",
                "\n",
                "# 3. Save results JSON\n",
                "results_path = RESULTS_DIR / \"ga_ppo_results.json\"\n",
                "with open(results_path, 'w') as f:\n",
                "    json.dump(results_dict, f, indent=2)\n",
                "print(f\"✓ Results saved to: {results_path}\")\n",
                "\n",
                "# 4. Print saved files summary\n",
                "print(f\"\\n{'─' * 80}\")\n",
                "print(\"SAVED FILES SUMMARY\")\n",
                "print(f\"{'─' * 80}\")\n",
                "print(f\"   Models:\")\n",
                "print(f\"     └── {model_path}\")\n",
                "print(f\"   Results:\")\n",
                "print(f\"     ├── {results_path}\")\n",
                "print(f\"     ├── {RESULTS_DIR / 'dataset_statistics.png'}\")\n",
                "print(f\"     ├── {RESULTS_DIR / 'ga_evolution.png'}\")\n",
                "print(f\"     └── {RESULTS_DIR / 'final_evaluation.png'}\")\n",
                "print(f\"{'─' * 80}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d2aeddc6",
            "metadata": {},
            "source": [
                "## 12. Summary - Copyable Results for Paper/Presentation\n",
                "\n",
                "Complete summary of the GA-optimized PPO experiment for documentation and publication."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f35e152e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# GENERATE COPYABLE SUMMARY FOR PAPER/PRESENTATION\n",
                "# ============================================================================\n",
                "\n",
                "summary_text = f\"\"\"\n",
                "{'═' * 80}\n",
                "EXPERIMENT SUMMARY: GA-OPTIMIZED PPO FOR 6G COGNITIVE RADIO DSA\n",
                "{'═' * 80}\n",
                "\n",
                " DATASET CHARACTERISTICS\n",
                "──────────────────────────\n",
                "• Training samples:        {spectrum_train.shape[0]:,} timesteps × {N_CHANNELS} channels\n",
                "• Test samples:            {spectrum_test.shape[0]:,} timesteps × {N_CHANNELS} channels\n",
                "• Mean spectrum occupancy: {np.mean(spectrum_train):.2%} (train), {np.mean(spectrum_test):.2%} (test)\n",
                "\n",
                " GENETIC ALGORITHM CONFIGURATION\n",
                "───────────────────────────────────\n",
                "• Population size:         {TRAINING_CONFIG.ga_population_size}\n",
                "• Generations:             {TRAINING_CONFIG.ga_generations}\n",
                "• Selection:               Tournament (size=3)\n",
                "• Crossover:               Uniform (p={TRAINING_CONFIG.ga_crossover_prob})\n",
                "• Mutation:                Gaussian + discrete (p={TRAINING_CONFIG.ga_mutation_prob})\n",
                "• Elitism:                 Top {TRAINING_CONFIG.ga_elitism} preserved\n",
                "• Training per candidate:  {TRAINING_CONFIG.ga_training_timesteps:,} timesteps\n",
                "• Total GA runtime:        {ga_total_time/60:.1f} minutes\n",
                "\n",
                " BEST HYPERPARAMETERS (GA-Optimized)\n",
                "──────────────────────────────────────\n",
                "• Learning rate:           {best_hyperparams['learning_rate']:.2e}\n",
                "• Gamma (γ):               {best_hyperparams['gamma']:.4f}\n",
                "• GAE Lambda (λ):          {best_hyperparams['gae_lambda']:.4f}\n",
                "• Clip range:              {best_hyperparams['clip_range']:.4f}\n",
                "• Entropy coefficient:     {best_hyperparams['ent_coef']:.4f}\n",
                "• Value function coef:     {best_hyperparams['vf_coef']:.4f}\n",
                "• N steps:                 {best_hyperparams['n_steps']}\n",
                "• Batch size:              {best_hyperparams['batch_size']}\n",
                "• N epochs:                {best_hyperparams['n_epochs']}\n",
                "• Architecture:            {best_hyperparams['architecture']}\n",
                "• Activation:              {best_hyperparams['activation']}\n",
                "• Switch penalty:          {best_hyperparams['switch_penalty']:.4f}\n",
                "• Collision penalty:       {best_hyperparams['collision_penalty']:.4f}\n",
                "\n",
                " PERFORMANCE COMPARISON (Test Set)\n",
                "─────────────────────────────────────\n",
                "┌────────────────┬───────────┬───────────────┬─────────────┐\n",
                "│ Metric         │ Random    │ Default PPO   │ GA-Optimized│\n",
                "├────────────────┼───────────┼───────────────┼─────────────┤\n",
                "│ Success Rate   │ {random_baseline['mean_success_rate']:>8.2%} │ {BASELINE_METRICS['success_rate']:>12.2%} │ {final_results['success_rate']:>10.2%} │\n",
                "│ Collision Rate │ {random_baseline['mean_collision_rate']:>8.2%} │ {BASELINE_METRICS['collision_rate']:>12.2%} │ {final_results['collision_rate']:>10.2%} │\n",
                "│ Switching Rate │ {random_baseline['mean_switching_rate']:>8.2%} │ {BASELINE_METRICS['switching_rate']:>12.2%} │ {final_results['switching_rate']:>10.2%} │\n",
                "│ Mean Reward    │ {random_baseline['mean_reward']:>8.1f} │ {BASELINE_METRICS['mean_reward']:>12.1f} │ {final_results['mean_reward']:>10.1f} │\n",
                "└────────────────┴───────────┴───────────────┴─────────────┘\n",
                "\n",
                " IMPROVEMENT OVER BASELINE\n",
                "────────────────────────────\n",
                "• Success Rate:    {final_results['success_rate'] - BASELINE_METRICS['success_rate']:+.2%}\n",
                "• Collision Rate:  {final_results['collision_rate'] - BASELINE_METRICS['collision_rate']:+.2%}\n",
                "• Switching Rate:  {final_results['switching_rate'] - BASELINE_METRICS['switching_rate']:+.2%}\n",
                "• Mean Reward:     {final_results['mean_reward'] - BASELINE_METRICS['mean_reward']:+.2f}\n",
                "\n",
                "⏱️ COMPUTATIONAL COST\n",
                "─────────────────────\n",
                "• GA optimization:         {ga_total_time/60:.1f} minutes\n",
                "• Final model training:    {final_train_time/60:.1f} minutes\n",
                "• Total timesteps trained: {TRAINING_CONFIG.final_training_timesteps:,}\n",
                "\n",
                " OUTPUT FILES\n",
                "───────────────\n",
                "• Model:   models/best_ppo_spectrum.zip\n",
                "• Results: results/ga_ppo_results.json\n",
                "• Plots:   results/dataset_statistics.png\n",
                "           results/ga_evolution.png\n",
                "           results/final_evaluation.png\n",
                "\n",
                "{'═' * 80}\n",
                "\"\"\"\n",
                "\n",
                "print(summary_text)\n",
                "\n",
                "# Also save summary as text file\n",
                "summary_path = RESULTS_DIR / \"experiment_summary.txt\"\n",
                "with open(summary_path, 'w') as f:\n",
                "    f.write(summary_text)\n",
                "print(f\"\\n✓ Summary saved to: {summary_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9cc3fdb5",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Conclusion\n",
                "\n",
                "This notebook demonstrated a complete pipeline for **Genetic Algorithm-based hyperparameter optimization of PPO** for **Dynamic Spectrum Access in 6G Cognitive Radio Networks**.\n",
                "\n",
                "### Key Contributions:\n",
                "1. **Custom Gymnasium Environment** (`SpectrumEnvFromDataset`) for spectrum access simulation\n",
                "2. **Configurable reward shaping** with success, collision, switching, and congestion penalties\n",
                "3. **DEAP-based GA** with tournament selection, uniform crossover, and Gaussian mutation\n",
                "4. **Comprehensive evaluation** comparing random baseline, default PPO, and GA-optimized PPO\n",
                "\n",
                "### Next Steps:\n",
                "- Extend to multi-agent scenarios (multiple Secondary Users)\n",
                "- Incorporate channel sensing uncertainty\n",
                "- Test with real-world spectrum occupancy traces\n",
                "- Deploy on edge devices for real-time decision making\n",
                "\n",
                "---\n",
                "*Generated for 6G Cognitive Radio Research Project*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}